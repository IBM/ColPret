{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "McGMVvA-Sfsi",
    "C11N9TcYS6GT",
    "tXQlCHTqS1ee",
    "yqnY9H6wUufF",
    "A5XLjSy0_7tN"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##### Loss Curves"
   ],
   "metadata": {
    "id": "TUwlV3bADRXd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from packaging import version\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import tensorboard as tb"
   ],
   "metadata": {
    "id": "M7IBmqGL__79"
   },
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msns\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m stats\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorboard\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtb\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorboard'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "major_ver, minor_ver, _ = version.parse(tb.__version__).release\n",
    "assert major_ver >= 2 and minor_ver >= 3, \\\n",
    "    \"This notebook requires TensorBoard 2.3 or later.\"\n",
    "print(\"TensorBoard version: \", tb.__version__)"
   ],
   "metadata": {
    "id": "jZeo3botDc4z",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a1f6adeb-10e8-49cf-d525-41bad147148e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "# https://stackoverflow.com/questions/42281844/what-is-the-mathematics-behind-the-smoothing-parameter-in-tensorboards-scalar\n",
    "def smooth(scalars: List[float], weight: float) -> List[float]:  # Weight between 0 and 1\n",
    "    last = scalars[0]  # First value in the plot (first timestep)\n",
    "    smoothed = list()\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  # Calculate smoothed value\n",
    "        smoothed.append(smoothed_val)                        # Save it\n",
    "        last = smoothed_val                                  # Anchor the last smoothed value\n",
    "\n",
    "    return smoothed\n",
    "\n",
    "# Uploaded using tensorboard dev upload --logdir tensorboard_8b7178b178boscar --name \"tensorboard_8b7178b178boscar\"\n",
    "MODEL_TO_ID_8C4 = {\n",
    "    \"tensorboard_8b7178b4b\": \"3jETknDLRWeDxO0TDXOFZw\",\n",
    "    \"tensorboard_8b7178b13b\": \"HaF19kmMSL2ce0w6tRx2wg\",\n",
    "    \"tensorboard_8b7178b25b\": \"QZIbYQR0SX2ZMBztYNEC9A\",\n",
    "    \"tensorboard_8b7178b35b\": \"nE2nk4p3TYGNgv0CzNZjtQ\",\n",
    "    \"tensorboard_8b7178b44b\": \"orJQHPulQkK81DtjN2o3mA\",\n",
    "    \"tensorboard_8b7178b58b\": \"BhJPvMhEQKe6g06qwFEv9A\",\n",
    "    \"tensorboard_8b7178b88b\": \"je8DgcWeSrCWYxQveCGyoQ\",\n",
    "    \"tensorboard_8b7178b178b\": \"PvKObUJwQeCAlZ9QUNPmYA\",\n",
    "}\n",
    "\n",
    "MODEL_TO_ID_8OSCAR = {\n",
    "    \"tensorboard_8b7178b4boscar\": \"tEQJvE2MRA2FvQy8E6ACNQ\",\n",
    "    \"tensorboard_8b7178b13boscar\": \"vPV3R60FQuqjo2AvkUM1Jw\",\n",
    "    \"tensorboard_8b7178b25boscar\": \"8J3jYtdCQBWfYqBYBdeH6A\",\n",
    "    \"tensorboard_8b7178b35boscar\": \"COB9LW80T6y7Uo3uqXswSw\",\n",
    "    \"tensorboard_8b7178b44boscar\": \"5cKZYdrtRze3pZxYmQzOkg\",\n",
    "    \"tensorboard_8b7178b58boscar\": \"oFgmb4EYTveq6gwurdELYA\",\n",
    "    \"tensorboard_8b7178b88boscar\": \"S4yATqIpTmmBLeQwzXOMTw\",\n",
    "    #\"tensorboard_8b7178b178boscar\": \"onhetwWrQ2arjiJzYmoqNA\",  # Only up to 70K steps\n",
    "    #\"tensorboard_8b7178b178boscar_val\": \"YwW56JkoRWKIDIlfwMCb4g\", # Different validation\n",
    "    \"tensorboard_8b7178b178boscar\": \"UD7KJYMWQBW1jeQv4dnFMg\",\n",
    "}\n",
    "\n",
    "\n",
    "MODEL_TO_ID_4C4 = {\n",
    "    \"tensorboard_4b284b1b9c4\": \"GJQnxhRbTDqIAESlJlqnyQ\",\n",
    "    \"tensorboard_4b284b6bc4\": \"Gpb9KXp8QxWoG04kuB3Q0Q\",\n",
    "    \"tensorboard_4b284b12bc4\": \"6u4kKYhOQ42K6FjlW4Mzfw\",\n",
    "    \"tensorboard_4b284b17bc4\": \"AV1DPG9DQ1ebQdhelka6rg\",\n",
    "    \"tensorboard_4b284b21bc4\": \"koZ9lRPxTnGW2DdG7TpTrw\",\n",
    "    \"tensorboard_4b284b28bc4\": \"IBK7bJaqRBKkAQ0OeKZYCg\",\n",
    "    \"tensorboard_4b284b42bc4\": \"cXJZmYyeQdynLdmBaWYRnA\",\n",
    "    \"tensorboard_4b284b84bc4\": \"dwcP4acZRYOWW3JNJJApeQ\",\n",
    "}\n",
    "\n",
    "MODEL_TO_ID_4OSCAR = {\n",
    "    \"tensorboard_4b284b1b9oscar\": \"Duo6twajQAq2JDkzNIBK7g\",\n",
    "    \"tensorboard_4b284b6boscar\": \"QWwPm1jrSrWu0LpQyGtYUw\",\n",
    "    \"tensorboard_4b284b12boscar\": \"BQ3IatWoR6SqtJvJwnAF3w\",\n",
    "    \"tensorboard_4b284b17boscar\": \"NJPrsDYsQHK1sESKXgwn0Q\",\n",
    "    \"tensorboard_4b284b21boscar\": \"VAghAG1mTAq2GoNTr5SqOQ\",\n",
    "    \"tensorboard_4b284b28boscar\": \"EYKl7llQSeuLnxF8CVu9RQ\",\n",
    "    \"tensorboard_4b284b42boscar\": \"Lsq5kVwNQkCwXUl8PFAQIg\",\n",
    "    \"tensorboard_4b284b84boscar\": \"3EJkoqmxQnmX1s0MuDHRTg\",\n",
    "}\n",
    "\n",
    "\n",
    "MODEL_TO_ID_2C4 = {\n",
    "    \"tensorboard_2b855b1b25c4\": \"w7KmvQJRRvyCAsd0DkLOwg\",\n",
    "    \"tensorboard_2b855b4bc4\": \"ZXJceKIQT0GOYcK27MaBBQ\",\n",
    "    \"tensorboard_2b855b9bc4\": \"pbQN2jUDRYGwcytlHPhl3A\",\n",
    "    \"tensorboard_2b855b11bc4\": \"FzZOyY97Qa6rvm93VYycaw\",\n",
    "    \"tensorboard_2b855b14bc4\": \"bPH3G4sgQbqvVuzx8GezXw\",\n",
    "    \"tensorboard_2b855b18bc4\": \"IgXi5yjpQXeXF8LGlK0Mag\",\n",
    "    \"tensorboard_2b855b28bc4\": \"AwpTAhvRRKSJ9wI0eQO3dw\",\n",
    "    \"tensorboard_2b855b55bc4\": \"Q6Lm5nBgRxeiKMHK6283Pw\",\n",
    "}\n",
    "\n",
    "MODEL_TO_ID_2OSCAR = {\n",
    "    \"tensorboard_2b855b1b25oscar\": \"TRM2S5j1QEWSwcBP7Qfb2A\",\n",
    "    \"tensorboard_2b855b4boscar\": \"1ZIDDurdS3O5FWJwNTmr7w\",\n",
    "    \"tensorboard_2b855b9boscar\": \"k2qH7TvzQ3CRfr1hrD7exg\",\n",
    "    \"tensorboard_2b855b11boscar\": \"M8lMcj3jSYmHn3Wba0kt0w\",\n",
    "    \"tensorboard_2b855b14boscar\": \"gzBUNp8eQc2UEOmWVerBxQ\",\n",
    "    \"tensorboard_2b855b18boscar\": \"wVxrmLoHRZaRRYer6Z1fQQ\",\n",
    "    \"tensorboard_2b855b28boscar\": \"N0UpKqiBQyGa5yLH3Kw9sA\",\n",
    "    \"tensorboard_2b855b55boscar\": \"gmv0q4gvTa6ANJmoC4dE2A\",\n",
    "}\n",
    "\n",
    "#### Select validation or training loss ###\n",
    "LOSS = \"validation\"#\"validation\" # training\n",
    "\n",
    "def get_data(model, model_id):\n",
    "    # For the first time download & filter it into a csv; then upload the csc to save time\n",
    "    experiment = tb.data.experimental.ExperimentFromDev(model_id)\n",
    "    df = experiment.get_scalars()\n",
    "\n",
    "    if (\"oscar\" in model) and (LOSS == \"validation\"):\n",
    "        tokens = df[df[\"tag\"] == f'lm-loss-{LOSS}/{LOSS}_oscar/lm loss {LOSS} vs tokens'].step.values\n",
    "        losses = df[df[\"tag\"] == f'lm-loss-{LOSS}/{LOSS}_oscar/lm loss {LOSS} vs tokens'].value.values\n",
    "    elif LOSS == \"training\":\n",
    "        tokens = df[df[\"tag\"] == f'lm-loss-{LOSS}/lm loss vs tokens'].step.values\n",
    "        losses = df[df[\"tag\"] == f'lm-loss-{LOSS}/lm loss vs tokens'].value.values\n",
    "    else:\n",
    "        tokens = df[df[\"tag\"] == f'lm-loss-{LOSS}/{LOSS}/lm loss {LOSS} vs tokens'].step.values\n",
    "        losses = df[df[\"tag\"] == f'lm-loss-{LOSS}/{LOSS}/lm loss {LOSS} vs tokens'].value.values\n",
    "\n",
    "    path = f\"{model}.csv\" if LOSS == 'validation' else f\"{model}_{LOSS}.csv\"\n",
    "\n",
    "    if (\"oscar\" in model) and (LOSS == \"validation\"):\n",
    "        df[df[\"tag\"] == f'lm-loss-{LOSS}/{LOSS}_oscar/lm loss {LOSS} vs tokens'].to_csv(path)\n",
    "    elif LOSS == \"training\":\n",
    "        df[df[\"tag\"] == f'lm-loss-{LOSS}/lm loss vs tokens'].to_csv(path)\n",
    "    else:\n",
    "        df[df[\"tag\"] == f'lm-loss-{LOSS}/{LOSS}/lm loss {LOSS} vs tokens'].to_csv(path)\n",
    "\n",
    "    return tokens, losses\n",
    "\n",
    "def get_data_csv(model, model_id, smooth_data=False):\n",
    "    if LOSS == \"training\":\n",
    "        if not(os.path.exists(f\"{model}_{LOSS}.csv\")):\n",
    "            !wget https://huggingface.co/datasets/datablations/scripts/raw/main/tb{LOSS}/{model}_{LOSS}.csv\n",
    "    else:\n",
    "        if not(os.path.exists(f\"{model}.csv\")):\n",
    "            !wget https://huggingface.co/datasets/datablations/scripts/raw/main/tb{LOSS}/{model}.csv\n",
    "    path = f\"{model}.csv\" if LOSS == 'validation' else f\"{model}_{LOSS}.csv\"\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    if LOSS == \"training\":\n",
    "        df['value'] = smooth(df[\"value\"].values.tolist(), weight=0.999)\n",
    "    elif smooth_data:\n",
    "        df[[\"value\"]] = df[[\"value\"]].apply(savgol_filter,  window_length=3, polyorder=2)\n",
    "        df['value'] = smooth(df[\"value\"].values.tolist(), weight=0.85)\n",
    "    return df.step.values, df.value.values\n",
    "\n",
    "#\"\"\"\n",
    "if False:\n",
    "    data_2c4 = []\n",
    "    for model, model_id in MODEL_TO_ID_2C4.items():\n",
    "        data_2c4.append(get_data(model, model_id))\n",
    "else:\n",
    "    data_2c4 = []\n",
    "    for model, model_id in MODEL_TO_ID_2C4.items():\n",
    "        data_2c4.append(get_data_csv(model, model_id))\n",
    "if False:\n",
    "    data_2oscar = []\n",
    "    for model, model_id in MODEL_TO_ID_2OSCAR.items():\n",
    "        data_2oscar.append(get_data(model, model_id))\n",
    "else:\n",
    "    data_2oscar = []\n",
    "    for model, model_id in MODEL_TO_ID_2OSCAR.items():\n",
    "        data_2oscar.append(get_data_csv(model, model_id))\n",
    "\n",
    "if False:\n",
    "    data_4c4 = []\n",
    "    for model, model_id in MODEL_TO_ID_4C4.items():\n",
    "        data_4c4.append(get_data(model, model_id))\n",
    "else:\n",
    "    data_4c4 = []\n",
    "    for model, model_id in MODEL_TO_ID_4C4.items():\n",
    "        data_4c4.append(get_data_csv(model, model_id))\n",
    "\n",
    "if False:\n",
    "    data_4oscar = []\n",
    "    for model, model_id in MODEL_TO_ID_4OSCAR.items():\n",
    "        data_4oscar.append(get_data(model, model_id))\n",
    "else:\n",
    "    data_4oscar = []\n",
    "    for model, model_id in MODEL_TO_ID_4OSCAR.items():\n",
    "\n",
    "        data_4oscar.append(get_data_csv(model, model_id))\n",
    "#\"\"\"\n",
    "if False:\n",
    "    data_8c4 = []\n",
    "    for model, model_id in MODEL_TO_ID_8C4.items():\n",
    "        data_8c4.append(get_data(model, model_id))\n",
    "else:\n",
    "    data_8c4 = []\n",
    "    for model, model_id in MODEL_TO_ID_8C4.items():\n",
    "        data_8c4.append(get_data_csv(model, model_id, smooth_data=True))\n",
    "\n",
    "if False:\n",
    "    data_8oscar = []\n",
    "    for model, model_id in MODEL_TO_ID_8OSCAR.items():\n",
    "        data_8oscar.append(get_data(model, model_id))\n",
    "else:\n",
    "    data_8oscar = []\n",
    "    for model, model_id in MODEL_TO_ID_8OSCAR.items():\n",
    "        data_8oscar.append(get_data_csv(model, model_id, smooth_data=True))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "abWdyOLYMKhy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a2296abf-96b5-4c37-9501-7167c20ecac7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "PREFIX_TO_EPOCHS = {\n",
    "    \"8b7178b4b\": 44,\n",
    "    \"8b7178b13b\": 14,\n",
    "    \"8b7178b25b\": 7,\n",
    "    \"8b7178b35b\": 5,\n",
    "    \"8b7178b44b\": 4,\n",
    "    \"8b7178b58b\": 3,\n",
    "    \"8b7178b88b\": 2,\n",
    "    \"8b7178b178b\": 1,\n",
    "\n",
    "    \"4b284b1b9\": 44,\n",
    "    \"4b284b6b\": 14,\n",
    "    \"4b284b12b\": 7,\n",
    "    \"4b284b17b\": 5,\n",
    "    \"4b284b21b\": 4,\n",
    "    \"4b284b28b\": 3,\n",
    "    \"4b284b42b\": 2,\n",
    "    \"4b284b84b\": 1,\n",
    "\n",
    "    \"2b855b1b25\": 44,\n",
    "    \"2b855b4b\": 14,\n",
    "    \"2b855b9b\": 7,\n",
    "    \"2b855b11b\": 5,\n",
    "    \"2b855b14b\": 4,\n",
    "    \"2b855b18b\": 3,\n",
    "    \"2b855b28b\": 2,\n",
    "    \"2b855b55b\": 1,\n",
    "}\n",
    "\n",
    "EPOCHS_TO_COLOR = {\n",
    "    44: \"#03071E\",\n",
    "    14: \"#6A040F\",\n",
    "    7: \"#D00000\",\n",
    "    5: \"#DC2F02\",\n",
    "    4: \"#E85D04\",\n",
    "    3: \"#F48C06\",\n",
    "    2: \"#FAA307\",\n",
    "    1: \"#FFBA08\",\n",
    "}\n",
    "\n",
    "\n",
    "TOKENS_TICKS_8 = [\n",
    "    5e9,\n",
    "    #1e9,\n",
    "    #20e9,\n",
    "    40e9,\n",
    "    #60e9,\n",
    "    #80e9,\n",
    "    100e9,\n",
    "    #120e9,\n",
    "    140e9,\n",
    "    #160e9,\n",
    "    180e9,\n",
    "]\n",
    "\n",
    "TOKENS_STR_8 = [\n",
    "    \"5B\",\n",
    "    #\"1B\",\n",
    "    #\"20B\",\n",
    "    \"40B\",\n",
    "    #\"60B\",\n",
    "    #\"80B\",\n",
    "    \"100B\",\n",
    "    #\"120B\",\n",
    "    \"140B\",\n",
    "    #\"160B\",\n",
    "    \"180B\",\n",
    "]\n",
    "\n",
    "#TOKENS_TICKS_8 = [\n",
    "#    44e9,\n",
    "#    58e9,\n",
    "#    88e9,\n",
    "#    178e9,\n",
    "#]\n",
    "#TOKENS_STR_8 = [\n",
    "#    \"44B\",\n",
    "#    \"58B\",\n",
    "#    \"88B\",\n",
    "#    \"178B\",\n",
    "#]\n",
    "\n",
    "TOKENS_TICKS_4 = [\n",
    "    #1e9,\n",
    "    5e9,\n",
    "    #10e9,\n",
    "    #20e9,\n",
    "    25e9,\n",
    "    #30e9,\n",
    "    #40e9,\n",
    "    45e9,\n",
    "    #50e9,\n",
    "    #60e9,\n",
    "    65e9,\n",
    "    #70e9,\n",
    "    #80e9,\n",
    "    85e9,\n",
    "    #90e9,\n",
    "    #100e9\n",
    "]\n",
    "\n",
    "TOKENS_STR_4 = [\n",
    "    #\"1B\",\n",
    "    \"5B\",\n",
    "    #\"10B\",\n",
    "    #\"20B\",\n",
    "    \"25B\",\n",
    "    #\"30B\",\n",
    "    #\"40B\",\n",
    "    \"45B\",\n",
    "    #\"50B\",\n",
    "    #\"60B\",\n",
    "    \"65B\",\n",
    "    #\"70B\",\n",
    "    #\"80B\",\n",
    "    \"85B\",\n",
    "    #\"90B\"\n",
    "    #\"100B\",\n",
    "]\n",
    "\n",
    "TOKENS_TICKS_2 = [\n",
    "    #0e9,\n",
    "    5e9,\n",
    "    #10e9,\n",
    "    15e9,\n",
    "    #20e9,\n",
    "    25e9,\n",
    "    #30e9,\n",
    "    35e9,\n",
    "    #40e9,\n",
    "    45e9,\n",
    "    #50e9,\n",
    "    55e9,\n",
    "    #60e9,\n",
    "]\n",
    "\n",
    "TOKENS_STR_2 = [\n",
    "    #\"1B\",\n",
    "    \"5B\",\n",
    "    #\"10B\",\n",
    "    \"15B\",\n",
    "    #\"20B\",\n",
    "    \"25B\",\n",
    "    #\"30B\",\n",
    "    \"35B\",\n",
    "    #\"40B\",\n",
    "    \"45B\",\n",
    "    #\"50B\",\n",
    "    \"55B\",\n",
    "    #\"60B\"\n",
    "]\n",
    "\n",
    "\n",
    "FONTSIZE = 20\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(24, 10), facecolor='w', nrows=1, ncols=3, edgecolor='k', sharey=True)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "### Select C4 / OSCAR ###\n",
    "DATASET = \"c4\"#\"oscar\" # oscar\n",
    "if (LOSS == \"training\") and (DATASET == \"oscar\"):\n",
    "    MAX_MULT = 3.5\n",
    "else:\n",
    "    MAX_MULT = 1.5\n",
    "\n",
    "if DATASET == \"c4\":\n",
    "    GROUPS = [\n",
    "        (0, MODEL_TO_ID_2C4, data_2c4, TOKENS_TICKS_2, TOKENS_STR_2),\n",
    "        (1, MODEL_TO_ID_4C4, data_4c4, TOKENS_TICKS_4, TOKENS_STR_4),\n",
    "        (2, MODEL_TO_ID_8C4, data_8c4, TOKENS_TICKS_8, TOKENS_STR_8),\n",
    "    ]\n",
    "elif DATASET == \"oscar\":\n",
    "    GROUPS = [\n",
    "        (0, MODEL_TO_ID_2OSCAR, data_2oscar, TOKENS_TICKS_2, TOKENS_STR_2),\n",
    "        (1, MODEL_TO_ID_4OSCAR, data_4oscar, TOKENS_TICKS_4, TOKENS_STR_4),\n",
    "        (2, MODEL_TO_ID_8OSCAR, data_8oscar, TOKENS_TICKS_8, TOKENS_STR_8),\n",
    "    ]\n",
    "\n",
    "IDX_TO_TILE = {\n",
    "    0: \"2.8B parameters trained\\n for 55B tokens\",\n",
    "    1: \"4.2B parameters trained\\n for 84B tokens\",\n",
    "    2: \"8.7B parameters trained\\n for 178B tokens\",\n",
    "}\n",
    "\n",
    "for (i, models, data, ticks, ticks_str) in GROUPS:\n",
    "    for model, model_data in zip(models, data):\n",
    "        tokens = model_data[0]\n",
    "        losses = model_data[1]\n",
    "        prefix = model.split(\"_\")[1].replace(\"oscar\", \"\").replace(\"c4\", \"\")\n",
    "        epochs = PREFIX_TO_EPOCHS[prefix]\n",
    "        color = EPOCHS_TO_COLOR[epochs]\n",
    "        #suffix = \"epoch\"\n",
    "        axes[i].plot(tokens, losses, label=f\"{epochs}\", color=color, markersize=5)\n",
    "\n",
    "    axes[i].grid(axis='y')\n",
    "    axes[i].spines['right'].set_visible(False)\n",
    "    axes[i].spines['top'].set_visible(False)\n",
    "    axes[i].set_xticks(ticks, ticks_str, fontsize=FONTSIZE)\n",
    "    axes[i].set_xlim((min(ticks) - 5e9, max(ticks) + 5e9))\n",
    "\n",
    "    min_val = min(data, key=lambda x: x[1].min())[1].min()\n",
    "    axes[i].set_ylim((min_val - min_val * 0.01, min_val * MAX_MULT))\n",
    "\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=FONTSIZE)\n",
    "\n",
    "    #if i > 2:\n",
    "    axes[i].set_xlabel(\"Training tokens\", fontsize=FONTSIZE)\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(f\"{LOSS.capitalize()} loss\", fontsize=FONTSIZE)\n",
    "    if i == 3:\n",
    "        axes[i].set_ylabel(\"OSCAR Validation loss\", fontsize=FONTSIZE)\n",
    "\n",
    "    axes[i].set_title(IDX_TO_TILE[i], fontsize=FONTSIZE, fontweight=\"bold\", pad=24)\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "\n",
    "fig.legend(\n",
    "    handles[::-1],\n",
    "    labels[::-1],\n",
    "    frameon=False,\n",
    "    fontsize=FONTSIZE,\n",
    "    #ncol=8,\n",
    "    #loc=(0, 1.2),\n",
    "    ncol=8,\n",
    "    title=\"Epochs\",\n",
    "    title_fontproperties={'weight': 'bold', \"size\": FONTSIZE},\n",
    "    loc=\"lower center\",\n",
    ")\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, bottom=0.2)\n",
    "\n",
    "\n",
    "plt.savefig(f'{LOSS}_{DATASET}.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "CBwqdWrQbZBI",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "outputId": "5d92fba1-35a9-4649-f52f-5e9ad451d1f6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "PREFIX_TO_EPOCHS = {\n",
    "    \"8b7178b4b\": 44,\n",
    "    \"8b7178b13b\": 14,\n",
    "    \"8b7178b25b\": 7,\n",
    "    \"8b7178b35b\": 5,\n",
    "    \"8b7178b44b\": 4,\n",
    "    \"8b7178b58b\": 3,\n",
    "    \"8b7178b88b\": 2,\n",
    "    \"8b7178b178b\": 1,\n",
    "\n",
    "    \"4b284b1b9\": 44,\n",
    "    \"4b284b6b\": 14,\n",
    "    \"4b284b12b\": 7,\n",
    "    \"4b284b17b\": 5,\n",
    "    \"4b284b21b\": 4,\n",
    "    \"4b284b28b\": 3,\n",
    "    \"4b284b42b\": 2,\n",
    "    \"4b284b84b\": 1,\n",
    "\n",
    "    \"2b855b1b25\": 44,\n",
    "    \"2b855b4b\": 14,\n",
    "    \"2b855b9b\": 7,\n",
    "    \"2b855b11b\": 5,\n",
    "    \"2b855b14b\": 4,\n",
    "    \"2b855b18b\": 3,\n",
    "    \"2b855b28b\": 2,\n",
    "    \"2b855b55b\": 1,\n",
    "}\n",
    "\n",
    "EPOCHS_TO_COLOR = {\n",
    "    44: \"#03071E\",\n",
    "    14: \"#6A040F\",\n",
    "    7: \"#D00000\",\n",
    "    5: \"#DC2F02\",\n",
    "    4: \"#E85D04\",\n",
    "    3: \"#F48C06\",\n",
    "    2: \"#FAA307\",\n",
    "    1: \"#FFBA08\",\n",
    "}\n",
    "\n",
    "\n",
    "TOKENS_TICKS_8 = [\n",
    "    #1e9,\n",
    "    20e9,\n",
    "    #40e9,\n",
    "    60e9,\n",
    "    #80e9,\n",
    "    100e9,\n",
    "    #120e9,\n",
    "    140e9,\n",
    "    #160e9,\n",
    "    180e9,\n",
    "]\n",
    "\n",
    "TOKENS_STR_8 = [\n",
    "    #\"1B\",\n",
    "    \"20B\",\n",
    "    #\"40B\",\n",
    "    \"60B\",\n",
    "    #\"80B\",\n",
    "    \"100B\",\n",
    "    #\"120B\",\n",
    "    \"140B\",\n",
    "    #\"160B\",\n",
    "    \"180B\",\n",
    "]\n",
    "\n",
    "TOKENS_TICKS_4 = [\n",
    "    #1e9,\n",
    "    5e9,\n",
    "    #10e9,\n",
    "    #20e9,\n",
    "    25e9,\n",
    "    #30e9,\n",
    "    #40e9,\n",
    "    45e9,\n",
    "    #50e9,\n",
    "    #60e9,\n",
    "    65e9,\n",
    "    #70e9,\n",
    "    #80e9,\n",
    "    85e9,\n",
    "    #90e9,\n",
    "    #100e9\n",
    "]\n",
    "\n",
    "TOKENS_STR_4 = [\n",
    "    #\"1B\",\n",
    "    \"5B\",\n",
    "    #\"10B\",\n",
    "    #\"20B\",\n",
    "    \"25B\",\n",
    "    #\"30B\",\n",
    "    #\"40B\",\n",
    "    \"45B\",\n",
    "    #\"50B\",\n",
    "    #\"60B\",\n",
    "    \"65B\",\n",
    "    #\"70B\",\n",
    "    #\"80B\",\n",
    "    \"85B\",\n",
    "    #\"90B\"\n",
    "    #\"100B\",\n",
    "]\n",
    "\n",
    "TOKENS_TICKS_2 = [\n",
    "    #0e9,\n",
    "    5e9,\n",
    "    #10e9,\n",
    "    15e9,\n",
    "    #20e9,\n",
    "    25e9,\n",
    "    #30e9,\n",
    "    35e9,\n",
    "    #40e9,\n",
    "    45e9,\n",
    "    #50e9,\n",
    "    55e9,\n",
    "    #60e9,\n",
    "]\n",
    "\n",
    "TOKENS_STR_2 = [\n",
    "    #\"1B\",\n",
    "    \"5B\",\n",
    "    #\"10B\",\n",
    "    \"15B\",\n",
    "    #\"20B\",\n",
    "    \"25B\",\n",
    "    #\"30B\",\n",
    "    \"35B\",\n",
    "    #\"40B\",\n",
    "    \"45B\",\n",
    "    #\"50B\",\n",
    "    \"55B\",\n",
    "    #\"60B\"\n",
    "]\n",
    "\n",
    "\n",
    "FONTSIZE = 16\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20, 12), facecolor='w', nrows=2, ncols=3, edgecolor='k', sharey=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.3)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "GROUPS = [\n",
    "    (0, MODEL_TO_ID_2C4, data_2c4, TOKENS_TICKS_2, TOKENS_STR_2, 55e9),\n",
    "    (3, MODEL_TO_ID_2OSCAR, data_2oscar, TOKENS_TICKS_2, TOKENS_STR_2, 55e9),\n",
    "\n",
    "    (1, MODEL_TO_ID_4C4, data_4c4, TOKENS_TICKS_4, TOKENS_STR_4, 84e9),\n",
    "    (4, MODEL_TO_ID_4OSCAR, data_4oscar, TOKENS_TICKS_4, TOKENS_STR_4, 84e9),\n",
    "\n",
    "    (2, MODEL_TO_ID_8C4, data_8c4, TOKENS_TICKS_8, TOKENS_STR_8, 178e9),\n",
    "    (5, MODEL_TO_ID_8OSCAR, data_8oscar, TOKENS_TICKS_8, TOKENS_STR_8, 178e9),\n",
    "]\n",
    "\n",
    "IDX_TO_TILE = {\n",
    "    0: \"(a) 2.8B parameters trained on C4\",\n",
    "    1: \"(b) 4.2B parameters trained on C4\",\n",
    "    2: \"(c) 8.7B parameters trained on C4\",\n",
    "    3: \"(d) 2.8B parameters trained on OSCAR\",\n",
    "    4: \"(e) 4.2B parameters trained on OSCAR\",\n",
    "    5: \"(f) 8.7B parameters trained on OSCAR\",\n",
    "}\n",
    "\n",
    "for (i, models, data, ticks, ticks_str, total_tokens) in GROUPS:\n",
    "    for model, model_data in zip(models, data):\n",
    "        tokens = model_data[0]\n",
    "        losses = model_data[1]\n",
    "        prefix = model.split(\"_\")[1].replace(\"oscar\", \"\").replace(\"c4\", \"\")\n",
    "        epochs = PREFIX_TO_EPOCHS[prefix]\n",
    "        color = EPOCHS_TO_COLOR[epochs]\n",
    "\n",
    "        epochs_array = [toks / (total_tokens / epochs) for toks in tokens]\n",
    "        axes[i].plot(epochs_array, losses, label=f\"{epochs}\", color=color, markersize=5)\n",
    "\n",
    "\n",
    "    axes[i].grid(axis='y')\n",
    "    axes[i].grid(axis='x')\n",
    "\n",
    "    #axes[i].spines['right'].set_visible(False)\n",
    "    #axes[i].spines['top'].set_visible(False)\n",
    "    #axes[i].set_xticks(ticks, ticks_str, fontsize=FONTSIZE)\n",
    "    #axes[i].set_xlim((min(ticks) - 5e9, max(ticks) + 5e9))\n",
    "\n",
    "    min_val = min(data, key=lambda x: x[1].min())[1].min()\n",
    "    axes[i].set_ylim((min_val - min_val * 0.01, min_val * 1.5))\n",
    "\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=FONTSIZE)\n",
    "\n",
    "    axes[i].set_xticks(list(EPOCHS_TO_COLOR.keys())[2:], list(EPOCHS_TO_COLOR.keys())[2:], fontsize=FONTSIZE)\n",
    "    axes[i].set_xlim((0.01, list(EPOCHS_TO_COLOR.keys())[2] + 1.5 ))\n",
    "\n",
    "    if i > 2:\n",
    "        axes[i].set_xlabel(\"Epochs\", fontsize=FONTSIZE)\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"C4 Validation loss\", fontsize=FONTSIZE)\n",
    "    if i == 3:\n",
    "        axes[i].set_ylabel(\"OSCAR Validation loss\", fontsize=FONTSIZE)\n",
    "\n",
    "    axes[i].set_title(IDX_TO_TILE[i], fontsize=FONTSIZE, fontweight=\"bold\", pad=30)\n",
    "\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "\n",
    "axes[1].legend(\n",
    "    handles[::-1],\n",
    "    labels[::-1],\n",
    "    #frameon=False,\n",
    "    fontsize=FONTSIZE,\n",
    "    #ncol=8,\n",
    "    #loc=(0, 1.2),\n",
    "    ncol=2,\n",
    "    title=\"Epochs\",\n",
    "    title_fontproperties={'weight': 'bold', \"size\": FONTSIZE},\n",
    ")\n",
    "\n",
    "#axes[1].legend(\n",
    "#    *axes[0].get_legend_handles_labels(),\n",
    "#    frameon=False,\n",
    "#    fontsize=FONTSIZE,\n",
    "#)\n",
    "\n",
    "plt.savefig('validation_epochs_c4oscar.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "Xr-KZGyGbY74",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "1cb6346b-869d-4769-c1b4-55e682e67cbf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Presentation"
   ],
   "metadata": {
    "id": "iQ6iKyB50NzZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "PREFIX_TO_EPOCHS = {\n",
    "    \"8b7178b4b\": 44,\n",
    "    \"8b7178b13b\": 14,\n",
    "    \"8b7178b25b\": 7,\n",
    "    \"8b7178b35b\": 5,\n",
    "    \"8b7178b44b\": 4,\n",
    "    \"8b7178b58b\": 3,\n",
    "    \"8b7178b88b\": 2,\n",
    "    \"8b7178b178b\": 1,\n",
    "\n",
    "    \"4b284b1b9\": 44,\n",
    "    \"4b284b6b\": 14,\n",
    "    \"4b284b12b\": 7,\n",
    "    \"4b284b17b\": 5,\n",
    "    \"4b284b21b\": 4,\n",
    "    \"4b284b28b\": 3,\n",
    "    \"4b284b42b\": 2,\n",
    "    \"4b284b84b\": 1,\n",
    "\n",
    "    \"2b855b1b25\": 44,\n",
    "    \"2b855b4b\": 14,\n",
    "    \"2b855b9b\": 7,\n",
    "    \"2b855b11b\": 5,\n",
    "    \"2b855b14b\": 4,\n",
    "    \"2b855b18b\": 3,\n",
    "    \"2b855b28b\": 2,\n",
    "    \"2b855b55b\": 1,\n",
    "}\n",
    "\n",
    "EPOCHS_TO_COLOR = {\n",
    "    44: \"#03071E\",\n",
    "    14: \"#6A040F\",\n",
    "    7: \"#D00000\",\n",
    "    5: \"#DC2F02\",\n",
    "    4: \"#E85D04\",\n",
    "    3: \"#F48C06\",\n",
    "    2: \"#FAA307\",\n",
    "    1: \"#FFBA08\",\n",
    "}\n",
    "\n",
    "\n",
    "TOKENS_TICKS_8 = [\n",
    "    5e9,\n",
    "    #1e9,\n",
    "    #20e9,\n",
    "    40e9,\n",
    "    #60e9,\n",
    "    #80e9,\n",
    "    100e9,\n",
    "    #120e9,\n",
    "    140e9,\n",
    "    #160e9,\n",
    "    180e9,\n",
    "]\n",
    "\n",
    "TOKENS_STR_8 = [\n",
    "    \"5B\",\n",
    "    #\"1B\",\n",
    "    #\"20B\",\n",
    "    \"40B\",\n",
    "    #\"60B\",\n",
    "    #\"80B\",\n",
    "    \"100B\",\n",
    "    #\"120B\",\n",
    "    \"140B\",\n",
    "    #\"160B\",\n",
    "    \"180B\",\n",
    "]\n",
    "\n",
    "#TOKENS_TICKS_8 = [\n",
    "#    44e9,\n",
    "#    58e9,\n",
    "#    88e9,\n",
    "#    178e9,\n",
    "#]\n",
    "#TOKENS_STR_8 = [\n",
    "#    \"44B\",\n",
    "#    \"58B\",\n",
    "#    \"88B\",\n",
    "#    \"178B\",\n",
    "#]\n",
    "\n",
    "TOKENS_TICKS_4 = [\n",
    "    #1e9,\n",
    "    5e9,\n",
    "    #10e9,\n",
    "    #20e9,\n",
    "    25e9,\n",
    "    #30e9,\n",
    "    #40e9,\n",
    "    45e9,\n",
    "    #50e9,\n",
    "    #60e9,\n",
    "    65e9,\n",
    "    #70e9,\n",
    "    #80e9,\n",
    "    85e9,\n",
    "    #90e9,\n",
    "    #100e9\n",
    "]\n",
    "\n",
    "TOKENS_STR_4 = [\n",
    "    #\"1B\",\n",
    "    \"5B\",\n",
    "    #\"10B\",\n",
    "    #\"20B\",\n",
    "    \"25B\",\n",
    "    #\"30B\",\n",
    "    #\"40B\",\n",
    "    \"45B\",\n",
    "    #\"50B\",\n",
    "    #\"60B\",\n",
    "    \"65B\",\n",
    "    #\"70B\",\n",
    "    #\"80B\",\n",
    "    \"85B\",\n",
    "    #\"90B\"\n",
    "    #\"100B\",\n",
    "]\n",
    "\n",
    "TOKENS_TICKS_2 = [\n",
    "    #0e9,\n",
    "    5e9,\n",
    "    #10e9,\n",
    "    15e9,\n",
    "    #20e9,\n",
    "    25e9,\n",
    "    #30e9,\n",
    "    35e9,\n",
    "    #40e9,\n",
    "    45e9,\n",
    "    #50e9,\n",
    "    55e9,\n",
    "    #60e9,\n",
    "]\n",
    "\n",
    "TOKENS_STR_2 = [\n",
    "    #\"1B\",\n",
    "    \"5B\",\n",
    "    #\"10B\",\n",
    "    \"15B\",\n",
    "    #\"20B\",\n",
    "    \"25B\",\n",
    "    #\"30B\",\n",
    "    \"35B\",\n",
    "    #\"40B\",\n",
    "    \"45B\",\n",
    "    #\"50B\",\n",
    "    \"55B\",\n",
    "    #\"60B\"\n",
    "]\n",
    "\n",
    "\n",
    "FONTSIZE = 20\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(24, 10), facecolor='w', nrows=1, ncols=3, edgecolor='k', sharey=True)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "### Select C4 / OSCAR ###\n",
    "DATASET = \"c4\"#\"oscar\" # oscar\n",
    "if (LOSS == \"training\") and (DATASET == \"oscar\"):\n",
    "    MAX_MULT = 3.5\n",
    "else:\n",
    "    MAX_MULT = 1.5\n",
    "\n",
    "if DATASET == \"c4\":\n",
    "    GROUPS = [\n",
    "        (0, MODEL_TO_ID_2C4, data_2c4, TOKENS_TICKS_2, TOKENS_STR_2),\n",
    "        (1, MODEL_TO_ID_4C4, data_4c4, TOKENS_TICKS_4, TOKENS_STR_4),\n",
    "        (2, MODEL_TO_ID_8C4, data_8c4, TOKENS_TICKS_8, TOKENS_STR_8),\n",
    "    ]\n",
    "elif DATASET == \"oscar\":\n",
    "    GROUPS = [\n",
    "        (0, MODEL_TO_ID_2OSCAR, data_2oscar, TOKENS_TICKS_2, TOKENS_STR_2),\n",
    "        (1, MODEL_TO_ID_4OSCAR, data_4oscar, TOKENS_TICKS_4, TOKENS_STR_4),\n",
    "        (2, MODEL_TO_ID_8OSCAR, data_8oscar, TOKENS_TICKS_8, TOKENS_STR_8),\n",
    "    ]\n",
    "\n",
    "IDX_TO_TILE = {\n",
    "    0: \"2.8B parameters trained\\n for 55B tokens\",\n",
    "    1: \"4.2B parameters trained\\n for 84B tokens\",\n",
    "    2: \"8.7B parameters trained\\n for 178B tokens\",\n",
    "}\n",
    "\n",
    "for (i, models, data, ticks, ticks_str) in GROUPS:\n",
    "    for j, (model, model_data) in enumerate(zip(models, data)):\n",
    "        tokens = model_data[0]\n",
    "        losses = model_data[1]\n",
    "        prefix = model.split(\"_\")[1].replace(\"oscar\", \"\").replace(\"c4\", \"\")\n",
    "        epochs = PREFIX_TO_EPOCHS[prefix]\n",
    "        color = EPOCHS_TO_COLOR[epochs]\n",
    "        #suffix = \"epoch\"\n",
    "        if (j >= 0):\n",
    "            axes[i].plot(tokens, losses, label=f\"{epochs}\", color=color, markersize=5)\n",
    "\n",
    "    axes[i].grid(axis='y')\n",
    "    axes[i].spines['right'].set_visible(False)\n",
    "    axes[i].spines['top'].set_visible(False)\n",
    "    axes[i].set_xticks(ticks, ticks_str, fontsize=FONTSIZE)\n",
    "    axes[i].set_xlim((min(ticks) - 5e9, max(ticks) + 5e9))\n",
    "\n",
    "    min_val = min(data, key=lambda x: x[1].min())[1].min()\n",
    "    axes[i].set_ylim((min_val - min_val * 0.01, min_val * MAX_MULT))\n",
    "\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=FONTSIZE)\n",
    "\n",
    "    #if i > 2:\n",
    "    axes[i].set_xlabel(\"Training tokens\", fontsize=FONTSIZE)\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(f\"{LOSS.capitalize()} loss\", fontsize=FONTSIZE)\n",
    "    if i == 3:\n",
    "        axes[i].set_ylabel(\"OSCAR Validation loss\", fontsize=FONTSIZE)\n",
    "\n",
    "    axes[i].set_title(IDX_TO_TILE[i], fontsize=FONTSIZE, fontweight=\"bold\", pad=24)\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "\n",
    "fig.legend(\n",
    "    handles[::-1],\n",
    "    labels[::-1],\n",
    "    frameon=False,\n",
    "    fontsize=FONTSIZE,\n",
    "    #ncol=8,\n",
    "    #loc=(0, 1.2),\n",
    "    ncol=8,\n",
    "    title=\"Epochs\",\n",
    "    title_fontproperties={'weight': 'bold', \"size\": FONTSIZE},\n",
    "    loc=\"lower center\",\n",
    ")\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, bottom=0.2)\n",
    "\n",
    "\n",
    "plt.savefig(f'{LOSS}_{DATASET}.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "id": "Sue2uBWs0PCc",
    "outputId": "9bc1873c-8a3d-4328-d077-157faa706e9c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "PREFIX_TO_EPOCHS = {\n",
    "    \"8b7178b4b\": 44,\n",
    "    \"8b7178b13b\": 14,\n",
    "    \"8b7178b25b\": 7,\n",
    "    \"8b7178b35b\": 5,\n",
    "    \"8b7178b44b\": 4,\n",
    "    \"8b7178b58b\": 3,\n",
    "    \"8b7178b88b\": 2,\n",
    "    \"8b7178b178b\": 1,\n",
    "\n",
    "    \"4b284b1b9\": 44,\n",
    "    \"4b284b6b\": 14,\n",
    "    \"4b284b12b\": 7,\n",
    "    \"4b284b17b\": 5,\n",
    "    \"4b284b21b\": 4,\n",
    "    \"4b284b28b\": 3,\n",
    "    \"4b284b42b\": 2,\n",
    "    \"4b284b84b\": 1,\n",
    "\n",
    "    \"2b855b1b25\": 44,\n",
    "    \"2b855b4b\": 14,\n",
    "    \"2b855b9b\": 7,\n",
    "    \"2b855b11b\": 5,\n",
    "    \"2b855b14b\": 4,\n",
    "    \"2b855b18b\": 3,\n",
    "    \"2b855b28b\": 2,\n",
    "    \"2b855b55b\": 1,\n",
    "}\n",
    "\n",
    "EPOCHS_TO_COLOR = {\n",
    "    44: \"#03071E\",\n",
    "    14: \"#6A040F\",\n",
    "    7: \"#D00000\",\n",
    "    5: \"#DC2F02\",\n",
    "    4: \"#E85D04\",\n",
    "    3: \"#F48C06\",\n",
    "    2: \"#FAA307\",\n",
    "    1: \"#FFBA08\",\n",
    "}\n",
    "\n",
    "\n",
    "TOKENS_TICKS_8 = [\n",
    "    #1e9,\n",
    "    20e9,\n",
    "    #40e9,\n",
    "    60e9,\n",
    "    #80e9,\n",
    "    100e9,\n",
    "    #120e9,\n",
    "    140e9,\n",
    "    #160e9,\n",
    "    180e9,\n",
    "]\n",
    "\n",
    "TOKENS_STR_8 = [\n",
    "    #\"1B\",\n",
    "    \"20B\",\n",
    "    #\"40B\",\n",
    "    \"60B\",\n",
    "    #\"80B\",\n",
    "    \"100B\",\n",
    "    #\"120B\",\n",
    "    \"140B\",\n",
    "    #\"160B\",\n",
    "    \"180B\",\n",
    "]\n",
    "\n",
    "TOKENS_TICKS_4 = [\n",
    "    #1e9,\n",
    "    5e9,\n",
    "    #10e9,\n",
    "    #20e9,\n",
    "    25e9,\n",
    "    #30e9,\n",
    "    #40e9,\n",
    "    45e9,\n",
    "    #50e9,\n",
    "    #60e9,\n",
    "    65e9,\n",
    "    #70e9,\n",
    "    #80e9,\n",
    "    85e9,\n",
    "    #90e9,\n",
    "    #100e9\n",
    "]\n",
    "\n",
    "TOKENS_STR_4 = [\n",
    "    #\"1B\",\n",
    "    \"5B\",\n",
    "    #\"10B\",\n",
    "    #\"20B\",\n",
    "    \"25B\",\n",
    "    #\"30B\",\n",
    "    #\"40B\",\n",
    "    \"45B\",\n",
    "    #\"50B\",\n",
    "    #\"60B\",\n",
    "    \"65B\",\n",
    "    #\"70B\",\n",
    "    #\"80B\",\n",
    "    \"85B\",\n",
    "    #\"90B\"\n",
    "    #\"100B\",\n",
    "]\n",
    "\n",
    "TOKENS_TICKS_2 = [\n",
    "    #0e9,\n",
    "    5e9,\n",
    "    #10e9,\n",
    "    15e9,\n",
    "    #20e9,\n",
    "    25e9,\n",
    "    #30e9,\n",
    "    35e9,\n",
    "    #40e9,\n",
    "    45e9,\n",
    "    #50e9,\n",
    "    55e9,\n",
    "    #60e9,\n",
    "]\n",
    "\n",
    "TOKENS_STR_2 = [\n",
    "    #\"1B\",\n",
    "    \"5B\",\n",
    "    #\"10B\",\n",
    "    \"15B\",\n",
    "    #\"20B\",\n",
    "    \"25B\",\n",
    "    #\"30B\",\n",
    "    \"35B\",\n",
    "    #\"40B\",\n",
    "    \"45B\",\n",
    "    #\"50B\",\n",
    "    \"55B\",\n",
    "    #\"60B\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "GROUPS = [\n",
    "    (0, MODEL_TO_ID_2C4, data_2c4, TOKENS_TICKS_2, TOKENS_STR_2, 55e9),\n",
    "    (3, MODEL_TO_ID_2OSCAR, data_2oscar, TOKENS_TICKS_2, TOKENS_STR_2, 55e9),\n",
    "\n",
    "    (1, MODEL_TO_ID_4C4, data_4c4, TOKENS_TICKS_4, TOKENS_STR_4, 84e9),\n",
    "    (4, MODEL_TO_ID_4OSCAR, data_4oscar, TOKENS_TICKS_4, TOKENS_STR_4, 84e9),\n",
    "\n",
    "    (2, MODEL_TO_ID_8C4, data_8c4, TOKENS_TICKS_8, TOKENS_STR_8, 178e9),\n",
    "    (5, MODEL_TO_ID_8OSCAR, data_8oscar, TOKENS_TICKS_8, TOKENS_STR_8, 178e9),\n",
    "]\n",
    "\n",
    "IDX_TO_TILE = {\n",
    "    0: \"(a) 2.8B parameters trained on C4\",\n",
    "    1: \"(b) 4.2B parameters trained on C4\",\n",
    "    2: \"(c) 8.7B parameters trained on C4\",\n",
    "    3: \"(d) 2.8B parameters trained on OSCAR\",\n",
    "    4: \"(e) 4.2B parameters trained on OSCAR\",\n",
    "    5: \"(f) 8.7B parameters trained on OSCAR\",\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for (i, models, data, ticks, ticks_str, total_tokens) in GROUPS:\n",
    "    for model, model_data in zip(models, data):\n",
    "        tokens = model_data[0]\n",
    "        losses = model_data[1]\n",
    "        prefix = model.split(\"_\")[1].replace(\"oscar\", \"\").replace(\"c4\", \"\")\n",
    "        epochs = PREFIX_TO_EPOCHS[prefix]\n",
    "        color = EPOCHS_TO_COLOR[epochs]\n",
    "\n",
    "        epochs_array = [toks / (total_tokens / epochs) for toks in tokens]\n",
    "        # axes[i].plot(epochs_array, losses, label=f\"{epochs}\", color=color, markersize=5)\n",
    "        # print(model,total_tokens)\n",
    "        # print(MODEL_TO_ID_2C4)\n",
    "        data = \"c4\"\n",
    "        if \"oscar\" in model:\n",
    "          data = \"oscar\"\n",
    "\n",
    "        model_args = {\"tensorboard\":models[model]}\n",
    "        num_params = IDX_TO_TILE[i].split()[1]\n",
    "        tokens_per_epoch = total_tokens / epochs\n",
    "        checkpoint = \"https://huggingface.co/datablations/\"\n",
    "        if model in MODEL_TO_ID_8C4:\n",
    "          checkpoint += \"lm1-8b7-178b-c4-repetitions\"\n",
    "        elif model in MODEL_TO_ID_8OSCAR:\n",
    "          checkpoint += \"lm1-8b7-178b-oscar-repetitions\"\n",
    "        elif model in MODEL_TO_ID_4C4:\n",
    "          checkpoint += \"lm1-4b2-84b-c4-repetitions\"\n",
    "        elif model in MODEL_TO_ID_4OSCAR:\n",
    "          checkpoint += \"lm1-4b2-84b-oscar-repetitions\"\n",
    "        elif model in MODEL_TO_ID_2C4:\n",
    "          checkpoint += \"lm1-2b8-55b-c4-repetitions\"\n",
    "        elif model in MODEL_TO_ID_2OSCAR:\n",
    "          checkpoint += \"lm1-2b8-55b-oscar-repetitions\"\n",
    "        else:\n",
    "          raise NotImplementedError(model)\n",
    "        if num_params == \"2.8B\":\n",
    "          flops = 9.3e20\n",
    "        elif num_params == \"4.2B\":\n",
    "          flops = 2.1e21\n",
    "        elif num_params == \"8.7B\":\n",
    "          flops = 9.3e22\n",
    "        else:\n",
    "          print(num_params)\n",
    "        for token_num,loss in zip(tokens,losses):\n",
    "          cur_flop = flops*total_tokens/token_num\n",
    "          rows.append((data, epochs, token_num, loss, num_params, model_args, tokens_per_epoch, cur_flop, checkpoint))\n",
    "print(model)\n",
    "df = pd.DataFrame(rows, columns = [\"data\", \"epochs\", \"token_num\", \"loss\", \"num_params\", \"model_args\", \"tokens_per_epoch\", \"flops\", \"chekpoint\"])\n",
    "          # print(rows[-1])\n",
    "df.to_csv(\"datablations_losses.csv\")\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "print(MODEL_TO_ID_2C4)\n",
    "df\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "id": "f2H6rmdy8xG4",
    "outputId": "5f81a859-1518-431b-ddea-192642f6e5c7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Old"
   ],
   "metadata": {
    "id": "ijj-Q_iH9jqq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "PREFIX_TO_EPOCHS = {\n",
    "    \"8b7178b4b\": 44,\n",
    "    \"8b7178b13b\": 14,\n",
    "    \"8b7178b25b\": 7,\n",
    "    \"8b7178b35b\": 5,\n",
    "    \"8b7178b44b\": 4,\n",
    "    \"8b7178b58b\": 3,\n",
    "    \"8b7178b88b\": 2,\n",
    "    \"8b7178b178b\": 1,\n",
    "\n",
    "    \"4b284b1b9\": 44,\n",
    "    \"4b284b6b\": 14,\n",
    "    \"4b284b12b\": 7,\n",
    "    \"4b284b17b\": 5,\n",
    "    \"4b284b21b\": 4,\n",
    "    \"4b284b28b\": 3,\n",
    "    \"4b284b42b\": 2,\n",
    "    \"4b284b84b\": 1,\n",
    "\n",
    "    \"2b855b1b25\": 44,\n",
    "    \"2b855b4b\": 14,\n",
    "    \"2b855b9b\": 7,\n",
    "    \"2b855b11b\": 5,\n",
    "    \"2b855b14b\": 4,\n",
    "    \"2b855b18b\": 3,\n",
    "    \"2b855b28b\": 2,\n",
    "    \"2b855b55b\": 1,\n",
    "}\n",
    "\n",
    "EPOCHS_TO_COLOR = {\n",
    "    44: \"#03071E\",\n",
    "    14: \"#6A040F\",\n",
    "    7: \"#D00000\",\n",
    "    5: \"#DC2F02\",\n",
    "    4: \"#E85D04\",\n",
    "    3: \"#F48C06\",\n",
    "    2: \"#FAA307\",\n",
    "    1: \"#FFBA08\",\n",
    "}\n",
    "\n",
    "\n",
    "TOKENS_TICKS_8 = [\n",
    "    #1e9,\n",
    "    20e9,\n",
    "    #40e9,\n",
    "    60e9,\n",
    "    #80e9,\n",
    "    100e9,\n",
    "    #120e9,\n",
    "    140e9,\n",
    "    #160e9,\n",
    "    180e9,\n",
    "]\n",
    "\n",
    "TOKENS_STR_8 = [\n",
    "    #\"1B\",\n",
    "    \"20B\",\n",
    "    #\"40B\",\n",
    "    \"60B\",\n",
    "    #\"80B\",\n",
    "    \"100B\",\n",
    "    #\"120B\",\n",
    "    \"140B\",\n",
    "    #\"160B\",\n",
    "    \"180B\",\n",
    "]\n",
    "\n",
    "#TOKENS_TICKS_8 = [\n",
    "#    44e9,\n",
    "#    58e9,\n",
    "#    88e9,\n",
    "#    178e9,\n",
    "#]\n",
    "#TOKENS_STR_8 = [\n",
    "#    \"44B\",\n",
    "#    \"58B\",\n",
    "#    \"88B\",\n",
    "#    \"178B\",\n",
    "#]\n",
    "\n",
    "TOKENS_TICKS_4 = [\n",
    "    #1e9,\n",
    "    5e9,\n",
    "    #10e9,\n",
    "    #20e9,\n",
    "    25e9,\n",
    "    #30e9,\n",
    "    #40e9,\n",
    "    45e9,\n",
    "    #50e9,\n",
    "    #60e9,\n",
    "    65e9,\n",
    "    #70e9,\n",
    "    #80e9,\n",
    "    85e9,\n",
    "    #90e9,\n",
    "    #100e9\n",
    "]\n",
    "\n",
    "TOKENS_STR_4 = [\n",
    "    #\"1B\",\n",
    "    \"5B\",\n",
    "    #\"10B\",\n",
    "    #\"20B\",\n",
    "    \"25B\",\n",
    "    #\"30B\",\n",
    "    #\"40B\",\n",
    "    \"45B\",\n",
    "    #\"50B\",\n",
    "    #\"60B\",\n",
    "    \"65B\",\n",
    "    #\"70B\",\n",
    "    #\"80B\",\n",
    "    \"85B\",\n",
    "    #\"90B\"\n",
    "    #\"100B\",\n",
    "]\n",
    "\n",
    "TOKENS_TICKS_2 = [\n",
    "    #0e9,\n",
    "    5e9,\n",
    "    #10e9,\n",
    "    15e9,\n",
    "    #20e9,\n",
    "    25e9,\n",
    "    #30e9,\n",
    "    35e9,\n",
    "    #40e9,\n",
    "    45e9,\n",
    "    #50e9,\n",
    "    55e9,\n",
    "    #60e9,\n",
    "]\n",
    "\n",
    "TOKENS_STR_2 = [\n",
    "    #\"1B\",\n",
    "    \"5B\",\n",
    "    #\"10B\",\n",
    "    \"15B\",\n",
    "    #\"20B\",\n",
    "    \"25B\",\n",
    "    #\"30B\",\n",
    "    \"35B\",\n",
    "    #\"40B\",\n",
    "    \"45B\",\n",
    "    #\"50B\",\n",
    "    \"55B\",\n",
    "    #\"60B\"\n",
    "]\n",
    "\n",
    "\n",
    "FONTSIZE = 16\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20, 12), facecolor='w', nrows=2, ncols=3, edgecolor='k', sharey=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.3)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "GROUPS = [\n",
    "    (0, MODEL_TO_ID_2C4, data_2c4, TOKENS_TICKS_2, TOKENS_STR_2),\n",
    "    (3, MODEL_TO_ID_2OSCAR, data_2oscar, TOKENS_TICKS_2, TOKENS_STR_2),\n",
    "\n",
    "    (1, MODEL_TO_ID_4C4, data_4c4, TOKENS_TICKS_4, TOKENS_STR_4),\n",
    "    (4, MODEL_TO_ID_4OSCAR, data_4oscar, TOKENS_TICKS_4, TOKENS_STR_4),\n",
    "\n",
    "    (2, MODEL_TO_ID_8C4, data_8c4, TOKENS_TICKS_8, TOKENS_STR_8),\n",
    "    (5, MODEL_TO_ID_8OSCAR, data_8oscar, TOKENS_TICKS_8, TOKENS_STR_8),\n",
    "]\n",
    "\n",
    "IDX_TO_TILE = {\n",
    "    0: \"(a) 2.8B parameters trained on C4\",\n",
    "    1: \"(b) 4.2B parameters trained on C4\",\n",
    "    2: \"(c) 8.6B parameters trained on C4\",\n",
    "    3: \"(d) 2.8B parameters trained on OSCAR\",\n",
    "    4: \"(e) 4.2B parameters trained on OSCAR\",\n",
    "    5: \"(f) 8.6B parameters trained on OSCAR\",\n",
    "}\n",
    "\n",
    "for (i, models, data, ticks, ticks_str) in GROUPS:\n",
    "    for model, model_data in zip(models, data):\n",
    "        tokens = model_data[0]\n",
    "        losses = model_data[1]\n",
    "        prefix = model.split(\"_\")[1].replace(\"oscar\", \"\").replace(\"c4\", \"\")\n",
    "        epochs = PREFIX_TO_EPOCHS[prefix]\n",
    "        color = EPOCHS_TO_COLOR[epochs]\n",
    "        #suffix = \"epoch\"\n",
    "        axes[i].plot(tokens, losses, label=f\"{epochs}\", color=color, markersize=5)\n",
    "\n",
    "    axes[i].grid(axis='y')\n",
    "    axes[i].spines['right'].set_visible(False)\n",
    "    axes[i].spines['top'].set_visible(False)\n",
    "    axes[i].set_xticks(ticks, ticks_str, fontsize=FONTSIZE)\n",
    "    axes[i].set_xlim((min(ticks) - 5e9, max(ticks) + 5e9))\n",
    "\n",
    "    min_val = min(data, key=lambda x: x[1].min())[1].min()\n",
    "    #max_val = max(data, key=lambda x: x[1].max())[1].max()\n",
    "    #axes[i].set_ylim((min_val - min_val * 0.01, max_val - max_val * 0.3))\n",
    "    axes[i].set_ylim((min_val - min_val * 0.01, min_val * 1.2))\n",
    "\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=FONTSIZE)\n",
    "\n",
    "    if i > 2:\n",
    "        axes[i].set_xlabel(\"Training tokens\", fontsize=FONTSIZE)\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"C4 Validation loss\", fontsize=FONTSIZE)\n",
    "    if i == 3:\n",
    "        axes[i].set_ylabel(\"OSCAR Validation loss\", fontsize=FONTSIZE)\n",
    "\n",
    "    axes[i].set_title(IDX_TO_TILE[i], fontsize=FONTSIZE, fontweight=\"bold\", pad=30)\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "\n",
    "axes[0].legend(\n",
    "    handles[::-1],\n",
    "    labels[::-1],\n",
    "    #frameon=False,\n",
    "    fontsize=FONTSIZE,\n",
    "    #ncol=8,\n",
    "    #loc=(0, 1.2),\n",
    "    ncol=2,\n",
    "    title=\"Epochs\",\n",
    "    title_fontproperties={'weight': 'bold', \"size\": FONTSIZE},\n",
    ")\n",
    "\n",
    "plt.savefig('validation_c4oscar.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "id": "95DOB56ZmzF3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Individual plots"
   ],
   "metadata": {
    "id": "McGMVvA-Sfsi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(24, 8), facecolor='w', ncols=2, edgecolor='k', sharey=True)\n",
    "\n",
    "# https://coolors.co/palette/03071e-370617-6a040f-9d0208-d00000-dc2f02-e85d04-f48c06-faa307-ffba08\n",
    "COLOR_MAP = {\n",
    "    \"tensorboard_8b7178b25b\": '#03071E',\n",
    "    \"tensorboard_8b7178b35b\": '#6A040F',\n",
    "    \"tensorboard_8b7178b44b\": '#D00000',\n",
    "    \"tensorboard_8b7178b58b\": '#E85D04',\n",
    "    \"tensorboard_8b7178b88b\": '#FB8500',\n",
    "    #\"tensorboard_4b284b84bc4\": '#FFBA08',\n",
    "}\n",
    "\n",
    "EPOCHS = [7, 5, 4, 3, 2, 1]\n",
    "TOTAL_TOKENS = 178e9\n",
    "\n",
    "TOKENS_TICKS = [\n",
    "    1e9,\n",
    "    #10e9,\n",
    "    20e9,\n",
    "    #30e9,\n",
    "    40e9,\n",
    "    #50e9,\n",
    "    60e9,\n",
    "    #70e9,\n",
    "    80e9,\n",
    "    #90e9,\n",
    "    100e9,\n",
    "    #110e9,\n",
    "    120e9,\n",
    "    140e9,\n",
    "    160e9,\n",
    "    180e9,\n",
    "]\n",
    "\n",
    "TOKENS_STR = [\n",
    "    \"1B\",\n",
    "    #\"10B\",\n",
    "    \"20B\",\n",
    "    #\"30B\",\n",
    "    \"40B\",\n",
    "    #\"50B\",\n",
    "    \"60B\",\n",
    "    #\"70B\",\n",
    "    \"80B\",\n",
    "    #\"90B\",\n",
    "    \"100B\",\n",
    "    #\"110B\",\n",
    "    \"120B\",\n",
    "    \"140B\",\n",
    "    \"160B\",\n",
    "    \"180B\",\n",
    "]\n",
    "\n",
    "data = data_8c4.copy()\n",
    "\n",
    "for i, (model, color) in enumerate(COLOR_MAP.items()):\n",
    "    tokens = data[i][0]\n",
    "    losses = data[i][1]\n",
    "    axes[0].plot(tokens, losses, label=f\"{EPOCHS[i]} epoch(s)\", color=color, markersize=5)\n",
    "\n",
    "for i, (model, color) in enumerate(COLOR_MAP.items()):\n",
    "    tokens = data[i][0]\n",
    "    epochs = [toks / (TOTAL_TOKENS / EPOCHS[i]) for toks in tokens]\n",
    "    losses = data[i][1]\n",
    "    axes[1].plot(epochs, list(losses), label=f\"{EPOCHS[i]} epoch(s)\", color=color, markersize=5)\n",
    "\n",
    "axes[1].legend(\n",
    "    frameon=False,\n",
    "    #loc=(0.10, 1.15),\n",
    "    fontsize=20,\n",
    ")\n",
    "\n",
    "axes[0].set_xlabel(\"Training tokens\", fontsize=16)\n",
    "axes[0].set_ylabel(\"Validation loss\", fontsize=16)\n",
    "\n",
    "#axes[0].set_xscale('log')\n",
    "\n",
    "axes[0].set_xticks(TOKENS_TICKS, TOKENS_STR, fontsize=12)\n",
    "\n",
    "#axes[0].set_yticks([2.4, 2.6, 2.8, 3.0, 3.2], fontsize=12)\n",
    "#axes[1].set_xticks(list(range(8)), fontsize=12)\n",
    "\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=12)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "min_val = min(data, key=lambda x: x[1].min())[1].min()\n",
    "max_val = max(data, key=lambda x: x[1].max())[1].max()\n",
    "\n",
    "axes[0].set_ylim((min_val - min_val * 0.01, max_val - max_val * 0.15))\n",
    "axes[1].set_xlabel(\"Epochs\", fontsize=16)\n",
    "\n",
    "axes[0].grid(axis='y')\n",
    "axes[1].grid(axis='y')\n",
    "\n",
    "\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "\n",
    "plt.savefig('validation_8b7c4.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "djbSjA6iMmqi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(24, 8), facecolor='w', ncols=2, edgecolor='k', sharey=True)\n",
    "\n",
    "# https://coolors.co/palette/03071e-370617-6a040f-9d0208-d00000-dc2f02-e85d04-f48c06-faa307-ffba08\n",
    "COLOR_MAP = {\n",
    "    \"tensorboard_4b284b12bc4\": '#03071E',\n",
    "    \"tensorboard_4b284b17bc4\": '#6A040F',\n",
    "    \"tensorboard_4b284b21bc4\": '#D00000',\n",
    "    \"tensorboard_4b284b28bc4\": '#E85D04',\n",
    "    \"tensorboard_4b284b42bc4\": '#FB8500',\n",
    "    \"tensorboard_4b284b84bc4\": '#FFBA08',\n",
    "}\n",
    "\n",
    "EPOCHS = [7, 5, 4, 3, 2, 1]\n",
    "TOTAL_TOKENS = 84e9\n",
    "\n",
    "TOKENS_TICKS = [12e9, 17e9, 21e9, 28e9, 42e9, 84e9]\n",
    "TOKENS_STR = [\"12B\", \"17B\", \"21B\", \"28B\", \"42B\", \"84B\"]\n",
    "\n",
    "TOKENS_TICKS = [1e9, 10e9, 20e9, 30e9, 40e9, 50e9, 60e9, 70e9, 80e9, 90e9]\n",
    "TOKENS_STR = [\"1B\", \"10B\", \"20B\", \"30B\", \"40B\", \"50B\", \"60B\", \"70B\", \"80B\", \"90B\"]\n",
    "\n",
    "data = data_4c4.copy()\n",
    "\n",
    "for i, (model, color) in enumerate(COLOR_MAP.items()):\n",
    "    tokens = data[i][0]\n",
    "    losses = data[i][1]\n",
    "    axes[0].plot(tokens, losses, label=f\"{EPOCHS[i]} epoch(s)\", color=color, markersize=5)\n",
    "\n",
    "for i, (model, color) in enumerate(COLOR_MAP.items()):\n",
    "    tokens = data[i][0]\n",
    "    epochs = [toks / (TOTAL_TOKENS / EPOCHS[i]) for toks in tokens]\n",
    "    losses = data[i][1]\n",
    "    axes[1].plot(epochs, list(losses), label=f\"{EPOCHS[i]} epoch(s)\", color=color, markersize=5)\n",
    "\n",
    "axes[1].legend(\n",
    "    frameon=False,\n",
    "    #loc=(0.10, 1.15),\n",
    "    fontsize=20,\n",
    ")\n",
    "\n",
    "axes[0].set_xlabel(\"Training tokens\", fontsize=16)\n",
    "axes[0].set_ylabel(\"Validation loss\", fontsize=16)\n",
    "\n",
    "#axes[0].set_xscale('log')\n",
    "\n",
    "axes[0].set_xticks(TOKENS_TICKS, TOKENS_STR, fontsize=12)\n",
    "\n",
    "#axes[0].set_yticks([2.4, 2.6, 2.8, 3.0, 3.2], fontsize=12)\n",
    "#axes[1].set_xticks(list(range(8)), fontsize=12)\n",
    "\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=12)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "\n",
    "min_val = min(data, key=lambda x: x[1].min())[1].min()\n",
    "max_val = max(data, key=lambda x: x[1].max())[1].max()\n",
    "\n",
    "axes[0].set_ylim((min_val - min_val * 0.01, max_val - max_val * 0.25))\n",
    "axes[1].set_xlabel(\"Epochs\", fontsize=16)\n",
    "\n",
    "axes[0].grid(axis='y')\n",
    "axes[1].grid(axis='y')\n",
    "\n",
    "\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "\n",
    "plt.savefig('validation_4b2c4.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "o8rbIhHFNCCo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(24, 8), facecolor='w', ncols=2, edgecolor='k', sharey=True)\n",
    "\n",
    "# https://coolors.co/palette/03071e-370617-6a040f-9d0208-d00000-dc2f02-e85d04-f48c06-faa307-ffba08\n",
    "COLOR_MAP = {\n",
    "    \"tensorboard_4b284b12boscar\": '#03071E',\n",
    "    \"tensorboard_4b284b17boscar\": '#6A040F',\n",
    "    \"tensorboard_4b284b21boscar\": '#D00000',\n",
    "    \"tensorboard_4b284b28boscar\": '#E85D04',\n",
    "    \"tensorboard_4b284b42boscar\": '#FB8500',\n",
    "    \"tensorboard_4b284b84boscar\": '#FFBA08',\n",
    "}\n",
    "\n",
    "EPOCHS = [7, 5, 4, 3, 2, 1]\n",
    "TOTAL_TOKENS = 84e9\n",
    "\n",
    "TOKENS_TICKS = [1e9, 10e9, 20e9, 30e9, 40e9, 50e9, 60e9, 70e9, 80e9, 90e9]\n",
    "TOKENS_STR = [\"1B\", \"10B\", \"20B\", \"30B\", \"40B\", \"50B\", \"60B\", \"70B\", \"80B\", \"90B\"]\n",
    "\n",
    "\n",
    "data = data_4oscar.copy()\n",
    "\n",
    "for i, (model, color) in enumerate(COLOR_MAP.items()):\n",
    "    tokens = data[i][0]\n",
    "    losses = data[i][1]\n",
    "    axes[0].plot(tokens, losses, label=f\"{EPOCHS[i]} epoch(s)\", color=color, markersize=5)\n",
    "\n",
    "for i, (model, color) in enumerate(COLOR_MAP.items()):\n",
    "    tokens = data[i][0]\n",
    "    epochs = [toks / (TOTAL_TOKENS / EPOCHS[i]) for toks in tokens]\n",
    "    losses = data[i][1]\n",
    "    axes[1].plot(epochs, list(losses), label=f\"{EPOCHS[i]} epoch(s)\", color=color, markersize=5)\n",
    "\n",
    "axes[1].legend(\n",
    "    frameon=False,\n",
    "    #loc=(0.10, 1.15),\n",
    "    fontsize=20,\n",
    ")\n",
    "\n",
    "axes[0].set_xlabel(\"Training tokens\", fontsize=16)\n",
    "axes[0].set_ylabel(\"Validation loss\", fontsize=16)\n",
    "\n",
    "#axes[0].set_xscale('log')\n",
    "\n",
    "axes[0].set_xticks(TOKENS_TICKS, TOKENS_STR, fontsize=12)\n",
    "\n",
    "#axes[0].set_yticks([2.4, 2.6, 2.8, 3.0, 3.2], fontsize=12)\n",
    "#axes[1].set_xticks(list(range(8)), fontsize=12)\n",
    "\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=12)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "\n",
    "min_val = min(data, key=lambda x: x[1].min())[1].min()\n",
    "max_val = max(data, key=lambda x: x[1].max())[1].max()\n",
    "\n",
    "axes[0].set_ylim((min_val - min_val * 0.01, max_val - max_val * 0.25))\n",
    "axes[1].set_xlabel(\"Epochs\", fontsize=16)\n",
    "\n",
    "axes[0].grid(axis='y')\n",
    "axes[1].grid(axis='y')\n",
    "\n",
    "\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "\n",
    "plt.savefig('validation_4b2oscar.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "9o1Zt4xpBmte"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(24, 8), facecolor='w', ncols=2, edgecolor='k', sharey=True)\n",
    "\n",
    "# https://coolors.co/palette/03071e-370617-6a040f-9d0208-d00000-dc2f02-e85d04-f48c06-faa307-ffba08\n",
    "COLOR_MAP = {\n",
    "    \"tensorboard_2b855b1b25c4\": '#03071E',\n",
    "    \"tensorboard_2b855b4bc4\": '#370617',\n",
    "    \"tensorboard_2b855b9bc4\": '#6A040F',\n",
    "    \"tensorboard_2b855b11bc4\": '#9D0208',\n",
    "    \"tensorboard_2b855b14bc4\": '#D00000',\n",
    "    \"tensorboard_2b855b18bc4\": '#E85D04',\n",
    "    \"tensorboard_2b855b28bc4\": '#FB8500',\n",
    "    \"tensorboard_2b855b55bc4\": '#FFBA08',\n",
    "}\n",
    "\n",
    "data = data_2c4.copy()\n",
    "\n",
    "EPOCHS = [44, 14, 7, 5, 4, 3, 2, 1]\n",
    "TOTAL_TOKENS = 84e9\n",
    "\n",
    "TOKENS_TICKS = [12e9, 17e9, 21e9, 28e9, 42e9, 84e9]\n",
    "TOKENS_STR = [\"12B\", \"17B\", \"21B\", \"28B\", \"42B\", \"84B\"]\n",
    "\n",
    "TOKENS_TICKS = [1e9, 10e9, 20e9, 30e9, 40e9, 50e9, 60e9]#, 70e9, 80e9]\n",
    "TOKENS_STR = [\"1B\", \"10B\", \"20B\", \"30B\", \"40B\", \"50B\", \"60B\"]#, \"70B\", \"80B\"]\n",
    "\n",
    "\n",
    "for i, (model, color) in enumerate(COLOR_MAP.items()):\n",
    "    tokens = data[i][0]\n",
    "    losses = data[i][1]\n",
    "    axes[0].plot(tokens, losses, label=f\"{EPOCHS[i]} epoch(s)\", color=color, markersize=5)\n",
    "\n",
    "for i, (model, color) in enumerate(COLOR_MAP.items()):\n",
    "    tokens = data[i][0]\n",
    "    epochs = [toks / (TOTAL_TOKENS / EPOCHS[i]) for toks in tokens]\n",
    "    losses = data[i][1]\n",
    "    axes[1].plot(epochs, list(losses), label=f\"{EPOCHS[i]} epoch(s)\", color=color, markersize=5)\n",
    "\n",
    "axes[1].legend(\n",
    "    frameon=False,\n",
    "    #loc=(0.10, 1.15),\n",
    "    fontsize=20,\n",
    ")\n",
    "\n",
    "axes[0].set_xlabel(\"Training tokens\", fontsize=16)\n",
    "axes[0].set_ylabel(\"Validation loss\", fontsize=16)\n",
    "\n",
    "axes[0].set_xticks(TOKENS_TICKS, TOKENS_STR, fontsize=12)\n",
    "axes[1].set_xticks([0, 1, 2, 3, 4, 5, 6, 7], fontsize=12)\n",
    "axes[1].set_xlim((-0.5, 7.5))\n",
    "\n",
    "#axes[0].set_yticks([2.4, 2.6, 2.8, 3.0, 3.2], fontsize=12)\n",
    "#axes[1].set_xticks(list(range(8)), fontsize=12)\n",
    "\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=12)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "\n",
    "min_val = min(data, key=lambda x: x[1].min())[1].min()\n",
    "max_val = max(data, key=lambda x: x[1].max())[1].max()\n",
    "\n",
    "axes[0].set_ylim((min_val - min_val * 0.01, max_val - max_val * 0.35))\n",
    "axes[1].set_xlabel(\"Epochs\", fontsize=16)\n",
    "\n",
    "axes[0].grid(axis='y')\n",
    "axes[1].grid(axis='y')\n",
    "\n",
    "\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "\n",
    "plt.savefig('validation_2b8c4.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "id": "s8jZU6dZlzp1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(24, 8), facecolor='w', ncols=2, edgecolor='k', sharey=True)\n",
    "\n",
    "# https://coolors.co/palette/03071e-370617-6a040f-9d0208-d00000-dc2f02-e85d04-f48c06-faa307-ffba08\n",
    "COLOR_MAP = {\n",
    "    \"tensorboard_2b855b1b25oscar\": '#03071E',\n",
    "    \"tensorboard_2b855b4boscar\": '#370617',\n",
    "    \"tensorboard_2b855b9boscar\": '#6A040F',\n",
    "    \"tensorboard_2b855b11boscar\": '#9D0208',\n",
    "    \"tensorboard_2b855b14boscar\": '#D00000',\n",
    "    \"tensorboard_2b855b18boscar\": '#E85D04',\n",
    "    \"tensorboard_2b855b28boscar\": '#FB8500',\n",
    "    \"tensorboard_2b855b55boscar\": '#FFBA08',\n",
    "}\n",
    "\n",
    "data = data_2oscar.copy()\n",
    "\n",
    "EPOCHS = [44, 14, 7, 5, 4, 3, 2, 1]\n",
    "TOTAL_TOKENS = 84e9\n",
    "\n",
    "TOKENS_TICKS = [12e9, 17e9, 21e9, 28e9, 42e9, 84e9]\n",
    "TOKENS_STR = [\"12B\", \"17B\", \"21B\", \"28B\", \"42B\", \"84B\"]\n",
    "\n",
    "TOKENS_TICKS = [1e9, 10e9, 20e9, 30e9, 40e9, 50e9, 60e9]#, 70e9, 80e9]\n",
    "TOKENS_STR = [\"1B\", \"10B\", \"20B\", \"30B\", \"40B\", \"50B\", \"60B\"]#, \"70B\", \"80B\"]\n",
    "\n",
    "\n",
    "for i, (model, color) in enumerate(COLOR_MAP.items()):\n",
    "    tokens = data[i][0]\n",
    "    losses = data[i][1]\n",
    "    axes[0].plot(tokens, losses, label=f\"{EPOCHS[i]} epoch(s)\", color=color, markersize=5)\n",
    "\n",
    "for i, (model, color) in enumerate(COLOR_MAP.items()):\n",
    "    tokens = data[i][0]\n",
    "    epochs = [toks / (TOTAL_TOKENS / EPOCHS[i]) for toks in tokens]\n",
    "    losses = data[i][1]\n",
    "    axes[1].plot(epochs, list(losses), label=f\"{EPOCHS[i]} epoch(s)\", color=color, markersize=5)\n",
    "\n",
    "axes[1].legend(\n",
    "    frameon=False,\n",
    "    #loc=(0.10, 1.15),\n",
    "    fontsize=20,\n",
    ")\n",
    "\n",
    "axes[0].set_xlabel(\"Training tokens\", fontsize=16)\n",
    "axes[0].set_ylabel(\"Validation loss\", fontsize=16)\n",
    "\n",
    "#axes[0].set_xscale('log')\n",
    "\n",
    "axes[0].set_xticks(TOKENS_TICKS, TOKENS_STR, fontsize=12)\n",
    "axes[1].set_xticks([0, 1, 2, 3, 4, 5, 6, 7], fontsize=12)\n",
    "axes[1].set_xlim((-0.5, 7.5))\n",
    "\n",
    "#axes[0].set_yticks([2.4, 2.6, 2.8, 3.0, 3.2], fontsize=12)\n",
    "#axes[1].set_xticks(list(range(8)), fontsize=12)\n",
    "\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=12)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "\n",
    "min_val = min(data, key=lambda x: x[1].min())[1].min()\n",
    "max_val = max(data, key=lambda x: x[1].max())[1].max()\n",
    "\n",
    "axes[0].set_ylim((min_val - min_val * 0.01, max_val - max_val * 0.35))\n",
    "axes[1].set_xlabel(\"Epochs\", fontsize=16)\n",
    "\n",
    "axes[0].grid(axis='y')\n",
    "axes[1].grid(axis='y')\n",
    "\n",
    "\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "\n",
    "plt.savefig('validation_2b8oscar.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "id": "7fsCFg-GbCRw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "X5-o7SUwQf8h"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Single tuned prompt"
   ],
   "metadata": {
    "id": "Wb0VrN1L_99o"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "### Get Downstream evaluation of reproduced Scores ###\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "!GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/datablations/lm1-8b7-178b-oscar\n",
    "!cd lm1-8b7-178b-oscar; git pull\n",
    "\n",
    "!GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/datablations/lm1-2b8-55b-c4seeds\n",
    "!GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/datablations/lm1-2b8-55b-oscarseeds\n",
    "\n",
    "!GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/datablations/lm1-4b2-84b-c4seeds\n",
    "!GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/datablations/lm1-4b2-84b-oscarseeds\n",
    "\n",
    "TASK_TO_BASELINE = {\n",
    "    \"anli_r1\": 1/3,\n",
    "    \"anli_r2\": 1/3,\n",
    "    \"anli_r3\": 1/3,\n",
    "    \"arc_challenge\": 1/4,\n",
    "    \"arc_easy\": 1/4,\n",
    "    \"boolq\": 1/2,\n",
    "    \"cb\": 1/3,\n",
    "    \"copa\": 1/2,\n",
    "    \"hellaswag\": 1/4,\n",
    "    \"piqa\": 1/2,\n",
    "    \"rte\": 1/2,\n",
    "    \"sciq\": 1/4,\n",
    "    \"storycloze_2016\": 1/4,\n",
    "    \"winogrande\": 1/2,\n",
    "}\n",
    "\n",
    "REPS_TO_MODELS = {\n",
    "   \"lm1-2b8-55b-c4-repetitions\": {\n",
    "      44: \"2b855b1b25c4\",\n",
    "      14: \"2b855b4bc4\",\n",
    "      7: \"2b855b9bc4\",\n",
    "\t    5: \"2b855b11bc4\",\n",
    "      4: \"2b855b14bc4\",\n",
    "      3: \"2b855b18bc4\",\n",
    "      2: \"2b855b28bc4\",\n",
    "      1: \"2b855b55bc4\",\n",
    "  },\n",
    "  \"lm1-2b8-55b-oscar-repetitions\": {\n",
    "      44: \"2b855b1b25oscar\",\n",
    "      14: \"2b855b4boscar\",\n",
    "      7: \"2b855b9boscar\",\n",
    "\t    5: \"2b855b11boscar\",\n",
    "      4: \"2b855b14boscar\",\n",
    "      3: \"2b855b18boscar\",\n",
    "      2: \"2b855b28boscar\",\n",
    "      1: \"2b855b55boscar\",\n",
    "  },\n",
    "  \"lm1-4b2-84b-c4-repetitions\": {\n",
    "      44: \"4b284b1b9c4\",\n",
    "\t    14: \"4b284b6bc4\",\n",
    "      7: \"4b284b12bc4\",\n",
    "\t    5: \"4b284b17bc4\",\n",
    "      4: \"4b284b21bc4\",\n",
    "      3: \"4b284b28bc4\",\n",
    "      2: \"4b284b42bc4\",\n",
    "      1: \"4b284b84bc4v2\",\n",
    "  },\n",
    "  \"lm1-4b2-84b-oscar-repetitions\": {\n",
    "      44: \"4b284b1b9oscar\",\n",
    "\t    14: \"4b284b6boscar\",\n",
    "      7: \"4b284b12boscar\",\n",
    "\t    5: \"4b284b17boscar\",\n",
    "      4: \"4b284b21boscar\",\n",
    "      3: \"4b284b28boscar\",\n",
    "      2: \"4b284b42boscar\",\n",
    "      1: \"4b284b84boscarv2\",\n",
    "  },\n",
    "  \"lm1-8b7-178b-c4-repetitions\": {\n",
    "      7: \"8b7178b25b\",\n",
    "\t    5: \"8b7178b35b\",\n",
    "      4: \"8b7178b44b\",\n",
    "      3: \"8b7178b58b\",\n",
    "      2: \"8b7178b88b\",\n",
    "      1: \"8b7178b178b\",\n",
    "   },\n",
    "  \"lm1-8b7-178b-oscar-repetitions\": {\n",
    "      7: \"8b7178b25b\",\n",
    "      5: \"8b7178b35b\",\n",
    "      4: \"8b7178b44b\",\n",
    "      3: \"8b7178b58b\",\n",
    "      2: \"8b7178b88b\",\n",
    "      1: \"8b7178b178b\",\n",
    "  },\n",
    "}\n",
    "\n",
    "OPS_TO_SCORES = {}\n",
    "OPS_TO_FULL_SCORES = {}\n",
    "MODEL_TO_FEWSHOT_SCORES = {}\n",
    "\n",
    "SHOTS = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "for BASE_MODEL, DATA in REPS_TO_MODELS.items():\n",
    "    !GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/datablations/{BASE_MODEL}\n",
    "    !cd {BASE_MODEL}; git pull\n",
    "\n",
    "    if os.path.isdir(BASE_MODEL.replace(\"-repetitions\", \"seeds\")):\n",
    "        !mv {BASE_MODEL.replace(\"-repetitions\", \"seeds\")}/* {BASE_MODEL}/\n",
    "        DATA = {**DATA, **{f\"{REP}{seed}\": f\"{MODEL}seed{seed}\" for REP, MODEL in DATA.items() for seed in [1, 2, 3, 4]}}\n",
    "    for REP, MODEL in DATA.items():\n",
    "        MODEL_TO_FEWSHOT_SCORES.setdefault(BASE_MODEL, {})\n",
    "        MODEL_TO_FEWSHOT_SCORES[BASE_MODEL].setdefault(MODEL, [])\n",
    "\n",
    "        if (BASE_MODEL == \"lm1-8b7-178b-oscar-repetitions\") and (MODEL == \"8b7178b178b\"):\n",
    "            generation = pd.read_csv(f\"lm1-8b7-178b-oscar/evaluation/generation/merged.csv\")\n",
    "        else:\n",
    "            path = f\"{BASE_MODEL}/{MODEL}/evaluation/generation/merged.csv\"\n",
    "            if not os.path.exists(path):\n",
    "                print(\"Skipping: \", f\"{BASE_MODEL}/{MODEL}\")\n",
    "                continue\n",
    "            generation = pd.read_csv(path)\n",
    "            if len(generation) == 0:\n",
    "                print(\"Skipping: \", f\"{BASE_MODEL}/{MODEL}\")\n",
    "                continue\n",
    "\n",
    "        for SHOT in SHOTS:\n",
    "            if (BASE_MODEL == \"lm1-8b7-178b-oscar-repetitions\") and (MODEL == \"8b7178b178b\"):\n",
    "                rankeval_files = glob.glob(f\"lm1-8b7-178b-oscar/evaluation/rankeval/*_{SHOT}.csv\")\n",
    "            else:\n",
    "                rankeval_files = glob.glob(f\"{BASE_MODEL}/{MODEL}/evaluation/rankeval/*_{SHOT}.csv\")\n",
    "\n",
    "            assert len(rankeval_files) == 1, f\"{rankeval_files}\"\n",
    "            rankeval = pd.read_csv(rankeval_files[0])\n",
    "\n",
    "            # Rescale to 0 - 1, where 0 is random performance\n",
    "            rankeval[\"normalized\"] = rankeval.apply(lambda x: (x[\"value\"] - TASK_TO_BASELINE[x[\"task\"]]) / (1 - TASK_TO_BASELINE[x[\"task\"]]), axis=1)\n",
    "            rankeval = rankeval[rankeval[\"metric\"] == \"acc\"]\n",
    "            rankeval_scores = rankeval.normalized.values.tolist()\n",
    "\n",
    "            gen_sub = generation[generation[\"fewshots\"] == SHOT]\n",
    "            gen_sub = gen_sub[gen_sub[\"prompt\"] != \"median\"]\n",
    "            gen_sub = gen_sub[gen_sub[\"prompt\"] != \"average\"]\n",
    "\n",
    "            # 0 is already random performance, i.e. no rescaling necessary\n",
    "            generation_scores = gen_sub.value.values.tolist()\n",
    "            scores = rankeval_scores + generation_scores\n",
    "\n",
    "            if len(rankeval_scores) != 14: print(f\"Missing rankeval scores for {BASE_MODEL}/{MODEL}\")\n",
    "            if len(generation_scores) != 4: print(f\"Missing generation scores for {BASE_MODEL}/{MODEL}\")\n",
    "\n",
    "            average_score = sum(scores) / len(scores)\n",
    "\n",
    "            MODEL_TO_FEWSHOT_SCORES[BASE_MODEL][MODEL].append(average_score * 100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_FECT3IBsVNS",
    "outputId": "618afb8a-b362-4dec-a749-17fe9775f6e2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### One boxplot per group"
   ],
   "metadata": {
    "id": "C11N9TcYS6GT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List\n",
    "\n",
    "# https://stackoverflow.com/questions/42281844/what-is-the-mathematics-behind-the-smoothing-parameter-in-tensorboards-scalar\n",
    "def smooth(scalars: List[float], weight: float) -> List[float]:  # Weight between 0 and 1\n",
    "    last = scalars[0]  # First value in the plot (first timestep)\n",
    "    smoothed = list()\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  # Calculate smoothed value\n",
    "        smoothed.append(smoothed_val)                        # Save it\n",
    "        last = smoothed_val                                  # Anchor the last smoothed value\n",
    "    return smoothed\n",
    "\n",
    "FONTSIZE = 14\n",
    "\n",
    "for BASE_MODEL, MODEL_DICT in MODEL_TO_FEWSHOT_SCORES.items():\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    LOSSES = []\n",
    "    EPOCHS = []\n",
    "    ALL_SCORES = []\n",
    "    for MODEL, SCORES in MODEL_DICT.items():\n",
    "        !wget https://huggingface.co/datasets/datablations/scripts/raw/main/tensorboard_{MODEL}.csv\n",
    "\n",
    "        df = pd.read_csv(f\"tensorboard_{MODEL}.csv\", index_col=0)\n",
    "        df['value'] = smooth(df[\"value\"].values.tolist(), weight=0.85)\n",
    "        LOSSES.append(df.value.values.tolist()[-1])\n",
    "        # Get reps\n",
    "        EPOCHS.append({v: k for k, v in REPS_TO_MODELS[BASE_MODEL].items()}[MODEL])\n",
    "        ALL_SCORES.append(SCORES)\n",
    "\n",
    "    # Sort EPOCHS & everything like it\n",
    "    EPOCHS, LOSSES, ALL_SCORES = zip(*sorted(zip(EPOCHS, LOSSES, ALL_SCORES), key=lambda x: x[0]))\n",
    "\n",
    "    ax.plot(list(range(len(EPOCHS))), LOSSES, 'x', markersize=10, mew=4, color=\"#9D0208\", label=\"Loss\")\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "    bp = ax2.boxplot(\n",
    "        ALL_SCORES,\n",
    "        positions=list(range(len(EPOCHS))),\n",
    "        #widths=width(positions,w),\n",
    "        patch_artist=True,\n",
    "        vert=True,\n",
    "        # Folds back on itself\n",
    "        #notch=True,\n",
    "        #bootstrap=10000,\n",
    "        boxprops={'fill': None} # transparent https://stackoverflow.com/questions/32161921/matplotlib-how-to-have-a-transparent-box-plot-face-while-a-non-transparent-line\n",
    "    )\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor('#2A9404')\n",
    "        patch.set(color=\"#2A9404\", linewidth=2)\n",
    "    for median in bp['medians']:\n",
    "        median.set_color('#2A9404')\n",
    "    for median in bp['whiskers']:\n",
    "        median.set_color('#2A9404')\n",
    "    for median in bp['caps']:\n",
    "        median.set_color('#2A9404')\n",
    "    for median in bp['fliers']:\n",
    "        median.set_color('#2A9404')\n",
    "\n",
    "    ax.set_xlabel(\"Epochs\", fontsize=FONTSIZE)\n",
    "    ax.set_ylabel(\"Validation loss\", fontsize=FONTSIZE)\n",
    "    ax2.set_ylabel(\"Normalized average on 18 tasks (%)\", fontsize=FONTSIZE)\n",
    "\n",
    "    ax2.set_ylim(list(reversed(ax2.get_ylim())))\n",
    "\n",
    "    ax.set_xticks(list(range(len(EPOCHS))), EPOCHS, fontsize=FONTSIZE)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONTSIZE)\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=FONTSIZE)\n",
    "\n",
    "    ax.grid(axis='y')\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    # Add box to legend; https://stackoverflow.com/questions/47528955/adding-a-legend-to-a-matplotlib-boxplot-with-multiple-plots-on-same-axes\n",
    "    handles = handles[:1] + bp[\"boxes\"]\n",
    "    labels = [str(labels[0])] + [\"Performance\"] # + OPS\n",
    "    ax.legend(handles, labels, prop={'size': FONTSIZE+2}, title_fontproperties={'weight':'bold'})\n",
    "\n",
    "    plt.savefig(f\"epochs_performance_single_prompt_{BASE_MODEL}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MKqUodAwmBs6",
    "outputId": "d3ebed65-3fef-4968-f734-f1a5110a6be6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Simple boxplot"
   ],
   "metadata": {
    "id": "tXQlCHTqS1ee"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://coolors.co/palette/03071e-370617-6a040f-9d0208-d00000-dc2f02-e85d04-f48c06-faa307-ffba08\n",
    "COLOR_MAP = {\n",
    "    7: '#03071E',\n",
    "    5: '#6A040F',\n",
    "    4: '#D00000',\n",
    "    3: '#E85D04',\n",
    "    2: '#FB8500',\n",
    "    1: '#FFBA08',\n",
    "}\n",
    "\n",
    "LOSSES = [\n",
    "  2.525268077850342,\n",
    "  2.483349323272705,\n",
    "  2.4695968627929688,\n",
    "  2.4654414653778076,\n",
    "  2.468310832977295,\n",
    "  2.4483046531677246\n",
    "]\n",
    "\n",
    "EPOCHS = [7, 5, 4, 3, 2, 1]\n",
    "\n",
    "PARAMS_TICKS = [100e6, 300e6, 1e9, 3e9, 6e9, 30e9]\n",
    "PARAMS_STR = [\"100M\", \"300M\", \"1B\", \"3B\", \"6B\", \"30B\"]\n",
    "\n",
    "\n",
    "LOSS_MIN = 1.8\n",
    "LOSS_MAX = 2.9\n",
    "\n",
    "SHOTS = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))#, nrows=2, ncols=2)\n",
    "\n",
    "\n",
    "ax.plot(EPOCHS, LOSSES, 'x', markersize=10, mew=4, color=\"#9D0208\", label=\"Loss\")\n",
    "ax2 = ax.twinx()\n",
    "ax2.boxplot(MODEL_TO_FEWSHOT_SCORES['lm1-4b2-84b-c4-repetitions'].values(), positions=list(reversed(EPOCHS)))\n",
    "\n",
    "ax.set_xlabel(\"Epochs\", fontsize=12)\n",
    "ax.set_ylabel(\"Validation loss\", fontsize=12)\n",
    "ax2.set_ylabel(\"Rescaled performance\", fontsize=12)\n",
    "\n",
    "ax.set_xticks(list(reversed(EPOCHS)), fontsize=12)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "\n",
    "ax.grid(axis='y')\n",
    "\n",
    "ax.legend(fontsize=12)\n",
    "plt.savefig(\"epochs_performance_single_prompt.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "fJpaQa1hugI2",
    "outputId": "c81b9e9b-81ee-4bb2-cee6-f5820e85d84c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Barplot"
   ],
   "metadata": {
    "id": "ybkGl9OCS3Yy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Bar plot instead with line being variance across multiple prompts (except for 8b just put no bar)\n",
    "# group 1 of bars: epochs; group 2 of bars: shots; group 3 of bars: model params\n",
    "\n",
    "### x-axis: params ; y-axis: loss / perf ; std: seeds ; grouped by shots\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# https://coolors.co/palette/03071e-370617-6a040f-9d0208-d00000-dc2f02-e85d04-f48c06-faa307-ffba08\n",
    "\n",
    "\n",
    "PREFIX_TO_EPOCHS = {\n",
    "    \"8b7178b25b\": 7,\n",
    "    \"8b7178b35b\": 5,\n",
    "    \"8b7178b44b\": 4,\n",
    "    \"8b7178b58b\": 3,\n",
    "    \"8b7178b88b\": 2,\n",
    "    \"8b7178b178b\": 1,\n",
    "\n",
    "    \"4b284b1b9\": 44,\n",
    "    \"4b284b6b\": 14,\n",
    "    \"4b284b12b\": 7,\n",
    "    \"4b284b17b\": 5,\n",
    "    \"4b284b21b\": 4,\n",
    "    \"4b284b28b\": 3,\n",
    "    \"4b284b42b\": 2,\n",
    "    \"4b284b84b\": 1,\n",
    "\n",
    "    \"2b855b1b25\": 44,\n",
    "    \"2b855b4b\": 14,\n",
    "    \"2b855b9b\": 7,\n",
    "    \"2b855b11b\": 5,\n",
    "    \"2b855b14b\": 4,\n",
    "    \"2b855b18b\": 3,\n",
    "    \"2b855b28b\": 2,\n",
    "    \"2b855b55b\": 1,\n",
    "}\n",
    "\n",
    "EPOCHS_TO_COLOR = {\n",
    "    44: \"#03071E\",\n",
    "    14: \"#6A040F\",\n",
    "    7: \"#D00000\",\n",
    "    5: \"#DC2F02\",\n",
    "    4: \"#E85D04\",\n",
    "    3: \"#F48C06\",\n",
    "    2: \"#FAA307\",\n",
    "    1: \"#FFBA08\",\n",
    "}\n",
    "\n",
    "COLORS = list(reversed([\n",
    "#    '#03071E',\n",
    "    '#6A040F',\n",
    "    '#D00000',\n",
    "    '#E85D04',\n",
    "    '#FB8500',\n",
    "    \"#FAA307\",\n",
    "    '#FFBA08',\n",
    "]))\n",
    "\n",
    "FONTSIZE = 16\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20, 12), facecolor='w', nrows=2, ncols=3, edgecolor='k', sharey=False)\n",
    "axes = axes.flatten()\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.3)\n",
    "\n",
    "GROUPS = [\n",
    "    (0, \"lm1-2b8-55b-c4-repetitions\"),\n",
    "    (3, \"lm1-2b8-55b-oscar-repetitions\"),\n",
    "\n",
    "    (1, \"lm1-4b2-84b-c4-repetitions\"),\n",
    "    (4, \"lm1-4b2-84b-oscar-repetitions\"),\n",
    "\n",
    "    (2, \"lm1-8b7-178b-c4-repetitions\"),\n",
    "    (5, \"lm1-8b7-178b-oscar-repetitions\"),\n",
    "]\n",
    "\n",
    "IDX_TO_TILE = {\n",
    "    0: \"(a) 2.8B parameters, 55B tokens, C4 \",\n",
    "    1: \"(b) 4.2B parameters, 84B tokens, C4\",\n",
    "    2: \"(c) 8.6B parameters, 178B tokens, C4\",\n",
    "    3: \"(d) 2.8B parameters, 55B tokens, OSCAR\",\n",
    "    4: \"(e) 4.2B parameters, 84B tokens, OSCAR\",\n",
    "    5: \"(f) 8.6B parameters, 178B tokens, OSCAR\",\n",
    "}\n",
    "\n",
    "for i, base_model in GROUPS:\n",
    "\n",
    "    last_len = 0\n",
    "\n",
    "\n",
    "    epoch_to_models = {}\n",
    "    for model in MODEL_TO_FEWSHOT_SCORES[base_model]:\n",
    "        prefix = model.replace(\"oscar\",\"\").replace(\"c4\", \"\").replace(\"seed1\",\"\").replace(\"seed2\",\"\").replace(\"seed3\",\"\").replace(\"seed4\", \"\").replace(\"v2\", \"\")\n",
    "        epoch_to_models.setdefault(PREFIX_TO_EPOCHS[prefix], [])\n",
    "        if MODEL_TO_FEWSHOT_SCORES[base_model][model]:\n",
    "            epoch_to_models[PREFIX_TO_EPOCHS[prefix]].append(model)\n",
    "        else:\n",
    "            print(f\"Missing scores for {model}\")\n",
    "    epoch_to_models = dict(reversed(epoch_to_models.items()))\n",
    "    colors = [EPOCHS_TO_COLOR[epoch] for epoch in epoch_to_models]\n",
    "\n",
    "    for shots in list(range(0, 6)):\n",
    "        scores_group = []\n",
    "        scores_std_group = []\n",
    "        for epoch in epoch_to_models:\n",
    "            scores = [MODEL_TO_FEWSHOT_SCORES[base_model][model][shots] for model in epoch_to_models[epoch]]\n",
    "\n",
    "            scores_mean = np.mean(scores)\n",
    "            scores_std = np.std(scores)\n",
    "\n",
    "            scores_group.append(scores_mean)\n",
    "            scores_std_group.append(scores_std)\n",
    "\n",
    "        x_positions = list(range(last_len, last_len + len(scores_group)))\n",
    "\n",
    "        bar = axes[i].bar(\n",
    "            #list(range(last_len + shots, last_len + shots + len(scores_group))),\n",
    "            x_positions,\n",
    "            scores_group,\n",
    "            yerr=scores_std_group,\n",
    "            color=colors,\n",
    "            width=1,\n",
    "        )\n",
    "        #last_len += len(scores_group) + 1\n",
    "        last_len += len(x_positions) + 1\n",
    "        print(x_positions)\n",
    "\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=FONTSIZE)\n",
    "    if i > 2:\n",
    "        axes[i].set_xlabel(\"Fewshots\", fontsize=FONTSIZE)\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Normalized Average (%)\", fontsize=FONTSIZE)\n",
    "        axes[i].legend(\n",
    "            [x for x in bar],\n",
    "            [str(x) for x in epoch_to_models],\n",
    "            title=\"Epochs\",\n",
    "            fontsize=FONTSIZE,\n",
    "            frameon=False,\n",
    "            ncol=4,\n",
    "            title_fontproperties={'weight': 'bold', \"size\": FONTSIZE},\n",
    "            columnspacing=0.9,\n",
    "            loc=\"upper center\"\n",
    "        )\n",
    "        #list(range(0, 6)), ontsize=FONTSIZE)\n",
    "        #[x for x in bar], list(range(0, 6)), title=\"Epochs\", fontsize=FONTSIZE, ncol=6, loc=\"upper center\", frameon=False)\n",
    "    if i == 3:\n",
    "        axes[i].set_ylabel(\"Normalized Average (%)\", fontsize=FONTSIZE)\n",
    "\n",
    "    axes[i].set_ylim((10, 35))\n",
    "\n",
    "    axes[i].set_xticks(\n",
    "        [len(scores_group) // 2 + (j * (len(scores_group) + 2)) for j in range(6)], list(range(6))\n",
    "    )\n",
    "\n",
    "    axes[i].grid(axis='y')\n",
    "    axes[i].set_axisbelow(True)\n",
    "\n",
    "    #legend = axes[i].legend([x for x in bar], list(range(0, 6)), title=\"Epochs\", fontsize=FONTSIZE, ncol=6, loc=\"upper center\", frameon=False)\n",
    "\n",
    "    # https://stackoverflow.com/questions/12402561/how-to-set-font-size-of-matplotlib-axis-legend\n",
    "    #plt.setp(legend.get_title(), fontsize=FONTSIZE, fontweight=\"bold\")\n",
    "\n",
    "    #handles, labels = ax.get_legend_handles_labels()\n",
    "    # Add box to legend; https://stackoverflow.com/questions/47528955/adding-a-legend-to-a-matplotlib-boxplot-with-multiple-plots-on-same-axes\n",
    "    #handles = handles[:1] + bp[\"boxes\"]\n",
    "    #labels = [str(labels[0])] + [\"Performance\"] # + OPS\n",
    "    #ax.legend(handles, labels, prop={'size': 16}, title_fontproperties={'weight':'bold'})\n",
    "    #plt.setp(plt.gca().get_legend().get_texts(), fontsize='16')\n",
    "\n",
    "    axes[i].set_title(IDX_TO_TILE[i], fontsize=FONTSIZE-1, fontweight=\"bold\", pad=30)\n",
    "\n",
    "\n",
    "plt.savefig(f\"epochs_scores.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xSWepb6XTqM0",
    "outputId": "36934729-a7e1-4912-b4ea-cc67a2533d02"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Bar plot instead with line being variance across multiple prompts (except for 8b just put no bar)\n",
    "# group 1 of bars: epochs; group 2 of bars: shots; group 3 of bars: model params\n",
    "\n",
    "### x-axis: params ; y-axis: loss / perf ; std: seeds ; grouped by shots\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# https://coolors.co/palette/03071e-370617-6a040f-9d0208-d00000-dc2f02-e85d04-f48c06-faa307-ffba08\n",
    "\n",
    "\n",
    "PREFIX_TO_EPOCHS = {\n",
    "    \"8b7178b25b\": 7,\n",
    "    \"8b7178b35b\": 5,\n",
    "    \"8b7178b44b\": 4,\n",
    "    \"8b7178b58b\": 3,\n",
    "    \"8b7178b88b\": 2,\n",
    "    \"8b7178b178b\": 1,\n",
    "\n",
    "    \"4b284b1b9\": 44,\n",
    "    \"4b284b6b\": 14,\n",
    "    \"4b284b12b\": 7,\n",
    "    \"4b284b17b\": 5,\n",
    "    \"4b284b21b\": 4,\n",
    "    \"4b284b28b\": 3,\n",
    "    \"4b284b42b\": 2,\n",
    "    \"4b284b84b\": 1,\n",
    "\n",
    "    \"2b855b1b25\": 44,\n",
    "    \"2b855b4b\": 14,\n",
    "    \"2b855b9b\": 7,\n",
    "    \"2b855b11b\": 5,\n",
    "    \"2b855b14b\": 4,\n",
    "    \"2b855b18b\": 3,\n",
    "    \"2b855b28b\": 2,\n",
    "    \"2b855b55b\": 1,\n",
    "}\n",
    "\n",
    "EPOCHS_TO_COLOR = {\n",
    "    44: \"#03071E\",\n",
    "    14: \"#6A040F\",\n",
    "    7: \"#D00000\",\n",
    "    5: \"#DC2F02\",\n",
    "    4: \"#E85D04\",\n",
    "    3: \"#F48C06\",\n",
    "    2: \"#FAA307\",\n",
    "    1: \"#FFBA08\",\n",
    "}\n",
    "\n",
    "COLORS = list(reversed([\n",
    "#    '#03071E',\n",
    "    '#6A040F',\n",
    "    '#D00000',\n",
    "    '#E85D04',\n",
    "    '#FB8500',\n",
    "    \"#FAA307\",\n",
    "    '#FFBA08',\n",
    "]))\n",
    "\n",
    "FONTSIZE = 16\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20, 8), facecolor='w', nrows=1, ncols=2, edgecolor='k', sharey=True)\n",
    "axes = axes.flatten()\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.3)\n",
    "\n",
    "GROUPS = [\n",
    "    (0, \"lm1-2b8-55b-c4-repetitions\"),\n",
    "    (3, \"lm1-2b8-55b-oscar-repetitions\"),\n",
    "\n",
    "    (1, \"lm1-4b2-84b-c4-repetitions\"),\n",
    "    (4, \"lm1-4b2-84b-oscar-repetitions\"),\n",
    "\n",
    "    (2, \"lm1-8b7-178b-c4-repetitions\"),\n",
    "    (5, \"lm1-8b7-178b-oscar-repetitions\"),\n",
    "]\n",
    "\n",
    "GROUPS = [\n",
    "    (\"lm1-2b8-55b-c4-repetitions\", \"lm1-4b2-84b-c4-repetitions\", \"lm1-8b7-178b-c4-repetitions\"),\n",
    "    (\"lm1-2b8-55b-oscar-repetitions\", \"lm1-4b2-84b-oscar-repetitions\", \"lm1-8b7-178b-oscar-repetitions\")\n",
    "]\n",
    "\n",
    "IDX_TO_TILE = {\n",
    "    0: \"C4\",\n",
    "    1: \"OSCAR\",\n",
    "}\n",
    "\n",
    "\n",
    "for i, group in enumerate(GROUPS):\n",
    "\n",
    "    scores_group = []\n",
    "    scores_std_group = []\n",
    "    last_len = 0\n",
    "\n",
    "    for j, base_model in enumerate(group):\n",
    "\n",
    "        epoch_to_models = {}\n",
    "        for model in MODEL_TO_FEWSHOT_SCORES[base_model]:\n",
    "            prefix = model.replace(\"oscar\",\"\").replace(\"c4\", \"\").replace(\"seed1\",\"\").replace(\"seed2\",\"\").replace(\"seed3\",\"\").replace(\"seed4\", \"\").replace(\"v2\", \"\")\n",
    "            epoch_to_models.setdefault(PREFIX_TO_EPOCHS[prefix], [])\n",
    "            if MODEL_TO_FEWSHOT_SCORES[base_model][model]:\n",
    "                epoch_to_models[PREFIX_TO_EPOCHS[prefix]].append(model)\n",
    "            else:\n",
    "                print(f\"Missing scores for {model}\")\n",
    "        epoch_to_models = dict(reversed(epoch_to_models.items()))\n",
    "        colors = [EPOCHS_TO_COLOR[epoch] for epoch in epoch_to_models]\n",
    "\n",
    "        scores_all = []\n",
    "        # Iterathe through epochs -> Shots -> Seeds\n",
    "        for epoch in epoch_to_models:\n",
    "            scores_all_shots = []\n",
    "            for shots in list(range(0, 6)):\n",
    "                # Create list of shot scores of all models\n",
    "                scores = [MODEL_TO_FEWSHOT_SCORES[base_model][model][shots] for model in epoch_to_models[epoch]]\n",
    "                scores_all_shots.append(scores)\n",
    "            # Average shots for each seed model & append\n",
    "            scores_all_shots = [\n",
    "                sum([scores_all_shots[shot][i] for shot in list(range(0, 6))]) / len(list(range(0, 6)))\n",
    "                for i, model in enumerate(epoch_to_models[epoch])\n",
    "            ]\n",
    "\n",
    "            scores_all.append(scores_all_shots)\n",
    "\n",
    "        print(base_model, scores_all)\n",
    "        # Average seeds & compute std across seeds\n",
    "        scores_mean = [np.mean(x) for x in scores_all]\n",
    "        scores_std = [np.std(x) for x in scores_all]\n",
    "\n",
    "        x_positions = list(range(last_len, last_len + len(scores_mean)))\n",
    "\n",
    "        bar = axes[i].bar(\n",
    "            #list(range(last_len + shots, last_len + shots + len(scores_group))),\n",
    "            x_positions,\n",
    "            scores_mean,\n",
    "            yerr=scores_std,\n",
    "            color=colors,\n",
    "            width=1,\n",
    "            zorder=3,\n",
    "        )\n",
    "\n",
    "        last_len += len(x_positions) + 1\n",
    "        print(x_positions)\n",
    "\n",
    "        if (i == 0) and (j == 0):\n",
    "            plt.legend(\n",
    "                [x for x in bar],\n",
    "                [str(x) for x in epoch_to_models],\n",
    "                title=\"Epochs\",\n",
    "                fontsize=FONTSIZE,\n",
    "                frameon=False,\n",
    "                ncol=4,\n",
    "                title_fontproperties={'weight': 'bold', \"size\": FONTSIZE},\n",
    "                columnspacing=0.9,\n",
    "                loc=(-0.3, 0.9), #\"upper center\"\n",
    "\n",
    "            )\n",
    "\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=FONTSIZE)\n",
    "    axes[i].set_ylim((0, 35))\n",
    "\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Normalized Average (%)\", fontsize=FONTSIZE)\n",
    "        axes[i].spines[['right', 'top']].set_visible(False)\n",
    "    elif i == 1:\n",
    "        axes[i].spines[['left', 'right', 'top']].set_visible(False)\n",
    "        #axes[i].tick_params(\n",
    "        #axis='y',          # changes apply to the x-axis\n",
    "        #which='both',      # both major and minor ticks are affected\n",
    "        #bottom=False,      # ticks along the bottom edge are off\n",
    "        #top=False,         # ticks along the top edge are off\n",
    "        #labelbottom=False) # labels along the bottom edge are off\n",
    "        # https://stackoverflow.com/questions/12998430/remove-xticks-in-a-matplotlib-plot\n",
    "        axes[i].yaxis.set_ticks_position('none')\n",
    "\n",
    "\n",
    "    axes[i].set_xticks(\n",
    "        [3.5, 12.5, 20.5],\n",
    "        [\"2.8B parameters\\n55B tokens\", \"4.2B parameters\\n84B tokens\", \"8.6B parameters\\n178B tokens\"],\n",
    "        fontsize=FONTSIZE-2,\n",
    "        fontweight=\"bold\",\n",
    "        #pad=30,\n",
    "    )\n",
    "\n",
    "\n",
    "    #axes[i].set_xticks(\n",
    "    #    [len(scores_group) // 2 + (j * (len(scores_group) + 2)) for j in range(6)], list(range(6))\n",
    "    #)\n",
    "    #axes[i].grid(axis='y')\n",
    "    axes[i].set_axisbelow(True)\n",
    "\n",
    "    axes[i].set_title(IDX_TO_TILE[i], fontsize=FONTSIZE+4, fontweight=\"bold\", pad=20)\n",
    "\n",
    "#plt.annotate(\n",
    "#    r\"$\\}$\",\n",
    "#    fontsize=50,\n",
    "#    xy=(0.27, 0.77),\n",
    "#    xycoords='figure fraction',\n",
    "#    rotation=90,\n",
    "#    fontweight=\"light\",\n",
    "#)\n",
    "plt.annotate('<2%\\ndifference',\n",
    "            xy=(-0.975, 0.66),\n",
    "            xytext=(-0.975, 0.71),\n",
    "            xycoords='axes fraction',\n",
    "            fontsize=FONTSIZE,\n",
    "            fontweight=\"bold\",\n",
    "            ha='center', va='bottom',\n",
    "            #bbox=dict(boxstyle='square', fc='white'),\n",
    "            arrowprops=dict(arrowstyle='-[, widthB=2.5', lw=2.0)\n",
    ")\n",
    "\n",
    "\n",
    "plt.savefig(f\"epochs_scores.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767
    },
    "id": "WvfO847oLeNR",
    "outputId": "a30c58ca-9956-4894-9838-c286254e85cf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot with lines & margin of error instead\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# https://coolors.co/palette/03071e-370617-6a040f-9d0208-d00000-dc2f02-e85d04-f48c06-faa307-ffba08\n",
    "\n",
    "PREFIX_TO_EPOCHS = {\n",
    "    \"8b7178b25b\": 7,\n",
    "    \"8b7178b35b\": 5,\n",
    "    \"8b7178b44b\": 4,\n",
    "    \"8b7178b58b\": 3,\n",
    "    \"8b7178b88b\": 2,\n",
    "    \"8b7178b178b\": 1,\n",
    "\n",
    "    \"4b284b1b9\": 44,\n",
    "    \"4b284b6b\": 14,\n",
    "    \"4b284b12b\": 7,\n",
    "    \"4b284b17b\": 5,\n",
    "    \"4b284b21b\": 4,\n",
    "    \"4b284b28b\": 3,\n",
    "    \"4b284b42b\": 2,\n",
    "    \"4b284b84b\": 1,\n",
    "\n",
    "    \"2b855b1b25\": 44,\n",
    "    \"2b855b4b\": 14,\n",
    "    \"2b855b9b\": 7,\n",
    "    \"2b855b11b\": 5,\n",
    "    \"2b855b14b\": 4,\n",
    "    \"2b855b18b\": 3,\n",
    "    \"2b855b28b\": 2,\n",
    "    \"2b855b55b\": 1,\n",
    "}\n",
    "\n",
    "EPOCHS_TO_COLOR = {\n",
    "    44: \"#03071E\",\n",
    "    14: \"#6A040F\",\n",
    "    7: \"#D00000\",\n",
    "    5: \"#DC2F02\",\n",
    "    4: \"#E85D04\",\n",
    "    3: \"#F48C06\",\n",
    "    2: \"#FAA307\",\n",
    "    1: \"#FFBA08\",\n",
    "}\n",
    "\n",
    "COLORS = list(reversed([\n",
    "#    '#03071E',\n",
    "    '#6A040F',\n",
    "    '#D00000',\n",
    "    '#E85D04',\n",
    "    '#FB8500',\n",
    "    \"#FAA307\",\n",
    "    '#FFBA08',\n",
    "]))\n",
    "\n",
    "FONTSIZE = 16\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20, 8), facecolor='w', nrows=1, ncols=2, edgecolor='k', sharey=True)\n",
    "axes = axes.flatten()\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.3)\n",
    "\n",
    "\n",
    "GROUPS = [\n",
    "    (\"lm1-2b8-55b-c4-repetitions\", \"lm1-4b2-84b-c4-repetitions\", \"lm1-8b7-178b-c4-repetitions\"),\n",
    "    (\"lm1-2b8-55b-oscar-repetitions\", \"lm1-4b2-84b-oscar-repetitions\", \"lm1-8b7-178b-oscar-repetitions\")\n",
    "]\n",
    "\n",
    "IDX_TO_TILE = {\n",
    "    0: \"C4\",\n",
    "    1: \"OSCAR\",\n",
    "}\n",
    "\n",
    "\n",
    "for i, group in enumerate(GROUPS):\n",
    "\n",
    "    scores_group = []\n",
    "    scores_std_group = []\n",
    "    last_len = 0\n",
    "\n",
    "    for j, base_model in enumerate(group):\n",
    "\n",
    "        epoch_to_models = {}\n",
    "        for model in MODEL_TO_FEWSHOT_SCORES[base_model]:\n",
    "            prefix = model.replace(\"oscar\",\"\").replace(\"c4\", \"\").replace(\"seed1\",\"\").replace(\"seed2\",\"\").replace(\"seed3\",\"\").replace(\"seed4\", \"\").replace(\"v2\", \"\")\n",
    "            epoch_to_models.setdefault(PREFIX_TO_EPOCHS[prefix], [])\n",
    "            if MODEL_TO_FEWSHOT_SCORES[base_model][model]:\n",
    "                epoch_to_models[PREFIX_TO_EPOCHS[prefix]].append(model)\n",
    "            else:\n",
    "                print(f\"Missing scores for {model}\")\n",
    "        epoch_to_models = dict(reversed(epoch_to_models.items()))\n",
    "        colors = [EPOCHS_TO_COLOR[epoch] for epoch in epoch_to_models]\n",
    "\n",
    "        scores_all = []\n",
    "        # Iterathe through epochs -> Shots -> Seeds\n",
    "        for epoch in epoch_to_models:\n",
    "            scores_all_shots = []\n",
    "            for shots in list(range(0, 6)):\n",
    "                # Create list of shot scores of all models\n",
    "                scores = [MODEL_TO_FEWSHOT_SCORES[base_model][model][shots] for model in epoch_to_models[epoch]]\n",
    "                scores_all_shots.append(scores)\n",
    "            # Average shots for each seed model & append\n",
    "            scores_all_shots = [\n",
    "                sum([scores_all_shots[shot][i] for shot in list(range(0, 6))]) / len(list(range(0, 6)))\n",
    "                for i, model in enumerate(epoch_to_models[epoch])\n",
    "            ]\n",
    "\n",
    "            scores_all.append(scores_all_shots)\n",
    "\n",
    "        print(base_model, scores_all)\n",
    "        # Average seeds & compute std across seeds\n",
    "        scores_mean = np.array([np.mean(x) for x in scores_all])\n",
    "        scores_std = np.array([np.std(x) for x in scores_all])\n",
    "\n",
    "        x_positions = list(range(last_len, last_len + len(scores_mean)))\n",
    "\n",
    "        axes[i].plot(\n",
    "            np.log10(list(epoch_to_models.keys())),\n",
    "            #x_positions,\n",
    "            scores_mean,\n",
    "            #yerr=scores_std,\n",
    "            color=colors[j*2],\n",
    "            linewidth=3.0,\n",
    "            marker=\".\",\n",
    "            #width=1,\n",
    "            #zorder=3,\n",
    "        )\n",
    "        axes[i].fill_between(\n",
    "            np.log10(list(epoch_to_models.keys())),\n",
    "            scores_mean - (scores_std),\n",
    "            scores_mean + (scores_std),\n",
    "            alpha=0.3,\n",
    "            facecolor=colors[j*2],\n",
    "        )\n",
    "\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Normalized Average (%)\", fontsize=FONTSIZE)\n",
    "    axes[i].set_xlabel(\"Epochs\", fontsize=FONTSIZE)\n",
    "\n",
    "        #axes[i].spines[['right', 'top']].set_visible(False)\n",
    "    #elif i == 1:\n",
    "        #axes[i].spines[['left', 'right', 'top']].set_visible(False)\n",
    "        #axes[i].tick_params(\n",
    "        #axis='y',          # changes apply to the x-axis\n",
    "        #which='both',      # both major and minor ticks are affected\n",
    "        #bottom=False,      # ticks along the bottom edge are off\n",
    "        #top=False,         # ticks along the top edge are off\n",
    "        #labelbottom=False) # labels along the bottom edge are off\n",
    "        # https://stackoverflow.com/questions/12998430/remove-xticks-in-a-matplotlib-plot\n",
    "        #axes[i].yaxis.set_ticks_position('none')\n",
    "\n",
    "    axes[i].set_title(IDX_TO_TILE[i], fontsize=FONTSIZE+4, fontweight=\"bold\", pad=20)\n",
    "\n",
    "\n",
    "    axes[i].set_xticks(\n",
    "        np.log10([1, 2, 3, 4, 5, 7, 14, 44]),\n",
    "        [1, 2, 3, 4, 5, 7, 14, 44],\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(f\"epochs_scores.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "id": "Rre_GogX9uBW",
    "outputId": "86f19840-2f6b-4bf5-9ddf-9cf1d89875e7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot with lines & margin of error instead\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# https://coolors.co/palette/03071e-370617-6a040f-9d0208-d00000-dc2f02-e85d04-f48c06-faa307-ffba08\n",
    "\n",
    "PREFIX_TO_EPOCHS = {\n",
    "    \"8b7178b25b\": 7,\n",
    "    \"8b7178b35b\": 5,\n",
    "    \"8b7178b44b\": 4,\n",
    "    \"8b7178b58b\": 3,\n",
    "    \"8b7178b88b\": 2,\n",
    "    \"8b7178b178b\": 1,\n",
    "\n",
    "    \"4b284b1b9\": 44,\n",
    "    \"4b284b6b\": 14,\n",
    "    \"4b284b12b\": 7,\n",
    "    \"4b284b17b\": 5,\n",
    "    \"4b284b21b\": 4,\n",
    "    \"4b284b28b\": 3,\n",
    "    \"4b284b42b\": 2,\n",
    "    \"4b284b84b\": 1,\n",
    "\n",
    "    \"2b855b1b25\": 44,\n",
    "    \"2b855b4b\": 14,\n",
    "    \"2b855b9b\": 7,\n",
    "    \"2b855b11b\": 5,\n",
    "    \"2b855b14b\": 4,\n",
    "    \"2b855b18b\": 3,\n",
    "    \"2b855b28b\": 2,\n",
    "    \"2b855b55b\": 1,\n",
    "}\n",
    "\n",
    "EPOCHS_TO_COLOR = {\n",
    "    44: \"#03071E\",\n",
    "    14: \"#6A040F\",\n",
    "    7: \"#D00000\",\n",
    "    5: \"#DC2F02\",\n",
    "    4: \"#E85D04\",\n",
    "    3: \"#F48C06\",\n",
    "    2: \"#FAA307\",\n",
    "    1: \"#FFBA08\",\n",
    "}\n",
    "\n",
    "COLORS = list(reversed([\n",
    "#    '#03071E',\n",
    "    '#6A040F',\n",
    "    '#D00000',\n",
    "    '#E85D04',\n",
    "    '#FB8500',\n",
    "    \"#FAA307\",\n",
    "    '#FFBA08',\n",
    "]))\n",
    "\n",
    "FONTSIZE = 16\n",
    "\n",
    "#fig, axes = plt.subplots(figsize=(24, 12), facecolor='w', nrows=2, ncols=3, edgecolor='k', sharey=True)\n",
    "fig = plt.figure(layout='constrained', figsize=(24, 12))\n",
    "subfigs = fig.subfigures(2, 1)\n",
    "subfigs[0].suptitle('Models trained on C4', fontsize=FONTSIZE+6)\n",
    "subfigs[1].suptitle('Models trained on OSCAR', fontsize=FONTSIZE+6)\n",
    "\n",
    "axes_top = subfigs[0].subplots(1, 3)#, sharey=True)\n",
    "axes_bot = subfigs[1].subplots(1, 3)#, sharey=True)\n",
    "\n",
    "axes = list(axes_top.flatten()) + list(axes_bot.flatten())\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.3)\n",
    "\n",
    "\n",
    "\n",
    "GROUPS = [\n",
    "    (\"lm1-2b8-55b-c4-repetitions\",), (\"lm1-2b8-55b-oscar-repetitions\",),\n",
    "    (\"lm1-4b2-84b-c4-repetitions\",), (\"lm1-4b2-84b-oscar-repetitions\",),\n",
    "    (\"lm1-8b7-178b-c4-repetitions\",), (\"lm1-8b7-178b-oscar-repetitions\",),\n",
    "]\n",
    "\n",
    "GROUPS = [\n",
    "    (\"lm1-2b8-55b-c4-repetitions\",),\n",
    "    (\"lm1-4b2-84b-c4-repetitions\",),\n",
    "    (\"lm1-8b7-178b-c4-repetitions\",),\n",
    "    (\"lm1-2b8-55b-oscar-repetitions\",),\n",
    "    (\"lm1-4b2-84b-oscar-repetitions\",),\n",
    "    (\"lm1-8b7-178b-oscar-repetitions\",),\n",
    "]\n",
    "\n",
    "IDX_TO_TILE = {\n",
    "    0: \"C4\",\n",
    "    1: \"OSCAR\",\n",
    "}\n",
    "\n",
    "IDX_TO_TILE = {\n",
    "    0: \"(a) 2.8B parameters\",\n",
    "    1: \"(b) 4.2B parameters\",\n",
    "    2: \"(c) 8.6B parameters\",\n",
    "    3: \"(d) 2.8B parameters\",\n",
    "    4: \"(e) 4.2B parameters\",\n",
    "    5: \"(f) 8.6B parameters\",\n",
    "}\n",
    "\n",
    "\n",
    "for i, group in enumerate(GROUPS):\n",
    "\n",
    "    scores_group = []\n",
    "    scores_std_group = []\n",
    "    last_len = 0\n",
    "\n",
    "    for j, base_model in enumerate(group):\n",
    "\n",
    "        epoch_to_models = {}\n",
    "        for model in MODEL_TO_FEWSHOT_SCORES[base_model]:\n",
    "            prefix = model.replace(\"oscar\",\"\").replace(\"c4\", \"\").replace(\"seed1\",\"\").replace(\"seed2\",\"\").replace(\"seed3\",\"\").replace(\"seed4\", \"\").replace(\"v2\", \"\")\n",
    "            epoch_to_models.setdefault(PREFIX_TO_EPOCHS[prefix], [])\n",
    "            if MODEL_TO_FEWSHOT_SCORES[base_model][model]:\n",
    "                epoch_to_models[PREFIX_TO_EPOCHS[prefix]].append(model)\n",
    "            else:\n",
    "                print(f\"Missing scores for {model}\")\n",
    "        epoch_to_models = dict(reversed(epoch_to_models.items()))\n",
    "        colors = [EPOCHS_TO_COLOR[epoch] for epoch in epoch_to_models]\n",
    "\n",
    "        scores_all = []\n",
    "        # Iterathe through epochs -> Shots -> Seeds\n",
    "        for epoch in epoch_to_models:\n",
    "            scores_all_shots = []\n",
    "            for shots in list(range(0, 6)):\n",
    "                # Create list of shot scores of all models\n",
    "                scores = [MODEL_TO_FEWSHOT_SCORES[base_model][model][shots] for model in epoch_to_models[epoch]]\n",
    "                scores_all_shots.append(scores)\n",
    "            # Average shots for each seed model & append\n",
    "            scores_all_shots = [\n",
    "                sum([scores_all_shots[shot][i] for shot in list(range(0, 6))]) / len(list(range(0, 6)))\n",
    "                for i, model in enumerate(epoch_to_models[epoch])\n",
    "            ]\n",
    "\n",
    "            scores_all.append(scores_all_shots)\n",
    "\n",
    "        print(base_model, scores_all)\n",
    "        # Average seeds & compute std across seeds\n",
    "        scores_mean = np.array([np.mean(x) for x in scores_all])\n",
    "        scores_std = np.array([np.std(x) for x in scores_all])\n",
    "\n",
    "        x_positions = list(range(last_len, last_len + len(scores_mean)))\n",
    "\n",
    "        axes[i].errorbar(\n",
    "            np.log10(list(epoch_to_models.keys())),\n",
    "            scores_mean,\n",
    "            yerr=scores_std,\n",
    "            color=colors[j*2],\n",
    "            linewidth=3.0,\n",
    "            marker=\".\",\n",
    "            markersize=16,\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        axes[i].plot(\n",
    "            np.log10(list(epoch_to_models.keys())),\n",
    "            #x_positions,\n",
    "            scores_mean,\n",
    "            #yerr=scores_std,\n",
    "            color=colors[j*2],\n",
    "            linewidth=3.0,\n",
    "            marker=\".\",\n",
    "            markersize=16,\n",
    "            #width=1,\n",
    "            #zorder=3,\n",
    "        )\n",
    "        axes[i].fill_between(\n",
    "            np.log10(list(epoch_to_models.keys())),\n",
    "            scores_mean - (scores_std),\n",
    "            scores_mean + (scores_std),\n",
    "            alpha=0.3,\n",
    "            facecolor=colors[j*2],\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "    if i == 0 or i == 3:\n",
    "        axes[i].set_ylabel(\"Normalized Average (%)\", fontsize=FONTSIZE)\n",
    "    if i >=3:\n",
    "        axes[i].set_xlabel(\"Epochs\", fontsize=FONTSIZE)\n",
    "    if i == 2 or i == 5:\n",
    "        s, e = axes[i].get_ylim()\n",
    "        axes[i].set_ylim(s-4, e+4)\n",
    "\n",
    "        #axes[i].spines[['right', 'top']].set_visible(False)\n",
    "    #elif i == 1:\n",
    "        #axes[i].spines[['left', 'right', 'top']].set_visible(False)\n",
    "        #axes[i].tick_params(\n",
    "        #axis='y',          # changes apply to the x-axis\n",
    "        #which='both',      # both major and minor ticks are affected\n",
    "        #bottom=False,      # ticks along the bottom edge are off\n",
    "        #top=False,         # ticks along the top edge are off\n",
    "        #labelbottom=False) # labels along the bottom edge are off\n",
    "        # https://stackoverflow.com/questions/12998430/remove-xticks-in-a-matplotlib-plot\n",
    "        #axes[i].yaxis.set_ticks_position('none')\n",
    "\n",
    "    axes[i].set_title(IDX_TO_TILE[i], fontsize=FONTSIZE-4, fontweight=\"bold\", pad=16)\n",
    "\n",
    "    #if len(epoch_to_models) == 8:\n",
    "    axes[i].set_xticks(\n",
    "        #np.log10([1, 2, 3, 4, 5, 7, 14, 44]),\n",
    "        #[1, 2, 3, 4, 5, 7, 14, 44],\n",
    "        np.log10([1, 44]),\n",
    "        [1, 44],\n",
    "    )\n",
    "    #else:\n",
    "    #    axes[i].set_xticks(\n",
    "    #        np.log10([1, 2, 3, 4, 5, 7]),\n",
    "    #        [1, 2, 3, 4, 5, 7],\n",
    "    #    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(f\"epochs_scores.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "jQ_tfbJBr_cJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "subfigs[0][1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63VVG7Ehxv-m",
    "outputId": "67ed6c23-64a1-4980-f20b-b4739dfdf2a0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "`# Bar plot instead with line being variance across multiple prompts (except for 8b just put no bar)\n",
    "# group 1 of bars: epochs; group 2 of bars: shots; group 3 of bars: model params\n",
    "\n",
    "### x-axis: params ; y-axis: loss / perf ; std: seeds ; grouped by shots\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# https://coolors.co/palette/03071e-370617-6a040f-9d0208-d00000-dc2f02-e85d04-f48c06-faa307-ffba08\n",
    "\n",
    "\n",
    "PREFIX_TO_EPOCHS = {\n",
    "    \"8b7178b25b\": 7,\n",
    "    \"8b7178b35b\": 5,\n",
    "    \"8b7178b44b\": 4,\n",
    "    \"8b7178b58b\": 3,\n",
    "    \"8b7178b88b\": 2,\n",
    "    \"8b7178b178b\": 1,\n",
    "\n",
    "    \"4b284b12b\": 7,\n",
    "    \"4b284b17b\": 5,\n",
    "    \"4b284b21b\": 4,\n",
    "    \"4b284b28b\": 3,\n",
    "    \"4b284b42b\": 2,\n",
    "    \"4b284b84b\": 1,\n",
    "\n",
    "    \"2b855b1b25\": 44,\n",
    "    \"2b855b4b\": 14,\n",
    "    \"2b855b9b\": 7,\n",
    "    \"2b855b11b\": 5,\n",
    "    \"2b855b14b\": 4,\n",
    "    \"2b855b18b\": 3,\n",
    "    \"2b855b28b\": 2,\n",
    "    \"2b855b55b\": 1,\n",
    "}\n",
    "\n",
    "EPOCHS_TO_COLOR = {\n",
    "    44: \"#03071E\",\n",
    "    14: \"#6A040F\",\n",
    "    7: \"#D00000\",\n",
    "    5: \"#DC2F02\",\n",
    "    4: \"#E85D04\",\n",
    "    3: \"#F48C06\",\n",
    "    2: \"#FAA307\",\n",
    "    1: \"#FFBA08\",\n",
    "}\n",
    "\n",
    "COLORS = list(reversed([\n",
    "#    '#03071E',\n",
    "    '#6A040F',\n",
    "    '#D00000',\n",
    "    '#E85D04',\n",
    "    '#FB8500',\n",
    "    \"#FAA307\",\n",
    "    '#FFBA08',\n",
    "]))\n",
    "\n",
    "FONTSIZE = 16\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20, 8), facecolor='w', nrows=1, ncols=2, edgecolor='k', sharey=True)\n",
    "axes = axes.flatten()\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.3)\n",
    "\n",
    "GROUPS = [\n",
    "    (0, \"lm1-2b8-55b-c4-repetitions\"),\n",
    "    (3, \"lm1-2b8-55b-oscar-repetitions\"),\n",
    "\n",
    "    (1, \"lm1-4b2-84b-c4-repetitions\"),\n",
    "    (4, \"lm1-4b2-84b-oscar-repetitions\"),\n",
    "\n",
    "    (2, \"lm1-8b7-178b-c4-repetitions\"),\n",
    "    (5, \"lm1-8b7-178b-oscar-repetitions\"),\n",
    "]\n",
    "\n",
    "GROUPS = [\n",
    "    (\"lm1-2b8-55b-c4-repetitions\", \"lm1-4b2-84b-c4-repetitions\", \"lm1-8b7-178b-c4-repetitions\"),\n",
    "    (\"lm1-2b8-55b-oscar-repetitions\", \"lm1-4b2-84b-oscar-repetitions\", \"lm1-8b7-178b-oscar-repetitions\")\n",
    "]\n",
    "\n",
    "IDX_TO_TILE = {\n",
    "    0: \"C4\",\n",
    "    1: \"OSCAR\",\n",
    "}\n",
    "\n",
    "\n",
    "for i, group in enumerate(GROUPS):\n",
    "\n",
    "    scores_group = []\n",
    "    scores_std_group = []\n",
    "    last_len = 0\n",
    "\n",
    "    for j, base_model in enumerate(group):\n",
    "\n",
    "        epoch_to_models = {}\n",
    "        for model in MODEL_TO_FEWSHOT_SCORES[base_model]:\n",
    "            prefix = model.replace(\"oscar\",\"\").replace(\"c4\", \"\").replace(\"seed1\",\"\").replace(\"seed2\",\"\").replace(\"seed3\",\"\").replace(\"seed4\", \"\").replace(\"v2\", \"\")\n",
    "            epoch_to_models.setdefault(PREFIX_TO_EPOCHS[prefix], [])\n",
    "            if MODEL_TO_FEWSHOT_SCORES[base_model][model]:\n",
    "                epoch_to_models[PREFIX_TO_EPOCHS[prefix]].append(model)\n",
    "            else:\n",
    "                print(f\"Missing scores for {model}\")\n",
    "        epoch_to_models = dict(reversed(epoch_to_models.items()))\n",
    "        colors = [EPOCHS_TO_COLOR[epoch] for epoch in epoch_to_models]\n",
    "\n",
    "        scores_all = []\n",
    "        # Iterathe through epochs -> Shots -> Seeds\n",
    "        for epoch in epoch_to_models:\n",
    "            scores_all_shots = []\n",
    "            for shots in list(range(0, 6)):\n",
    "                # Create list of shot scores of all models\n",
    "                scores = [MODEL_TO_FEWSHOT_SCORES[base_model][model][shots] for model in epoch_to_models[epoch]]\n",
    "                scores_all_shots.append(scores)\n",
    "            # Average shots for each seed model & append\n",
    "            scores_all_shots = [\n",
    "                sum([scores_all_shots[shot][i] for shot in list(range(0, 6))]) / len(list(range(0, 6)))\n",
    "                for i, model in enumerate(epoch_to_models[epoch])\n",
    "            ]\n",
    "\n",
    "            scores_all.append(scores_all_shots)\n",
    "\n",
    "        print(base_model, scores_all)\n",
    "        # Average seeds & compute std across seeds\n",
    "        scores_mean = [np.mean(x) for x in scores_all]\n",
    "        scores_std = [np.std(x) for x in scores_all]\n",
    "\n",
    "        x_positions = list(range(last_len, last_len + len(scores_mean)))\n",
    "\n",
    "        bar = axes[i].boxplot(\n",
    "            #list(range(last_len + shots, last_len + shots + len(scores_group))),\n",
    "            scores_mean,\n",
    "            positions=x_positions,\n",
    "            yerr=scores_std,\n",
    "            color=colors,\n",
    "            width=1,\n",
    "        )\n",
    "\n",
    "        last_len += len(x_positions) + 1\n",
    "        print(x_positions)\n",
    "\n",
    "        if (i == 0) and (j == 0):\n",
    "            axes[i].legend(\n",
    "                [x for x in bar],\n",
    "                [str(x) for x in epoch_to_models],\n",
    "                title=\"Epochs\",\n",
    "                fontsize=FONTSIZE,\n",
    "                frameon=False,\n",
    "                ncol=4,\n",
    "                title_fontproperties={'weight': 'bold', \"size\": FONTSIZE},\n",
    "                columnspacing=0.9,\n",
    "                loc=\"upper center\"\n",
    "            )\n",
    "\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Normalized Average (%)\", fontsize=FONTSIZE)\n",
    "\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=FONTSIZE)\n",
    "\n",
    "    axes[i].set_ylim((10, 35))\n",
    "\n",
    "    axes[i].set_xticks(\n",
    "        [3.5, 11.5, 18.5],\n",
    "        [\"2.8B parameters\\n55B tokens\", \"4.2B parameters\\n84B tokens\", \"8.6B parameters\\n178B tokens\"],\n",
    "        fontsize=FONTSIZE-2,\n",
    "        fontweight=\"bold\",\n",
    "        #pad=30,\n",
    "    )\n",
    "\n",
    "    #axes[i].set_xticks(\n",
    "    #    [len(scores_group) // 2 + (j * (len(scores_group) + 2)) for j in range(6)], list(range(6))\n",
    "    #)\n",
    "    axes[i].grid(axis='y')\n",
    "    axes[i].set_axisbelow(True)\n",
    "\n",
    "    axes[i].set_title(IDX_TO_TILE[i], fontsize=FONTSIZE+4, fontweight=\"bold\", pad=20)\n",
    "\n",
    "plt.savefig(f\"epochs_scores.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "bqH218oQgTm3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q --upgrade plotly\n",
    "!pip install -q pyyaml==5.4.1  # plotly dependency workaround\n",
    "!pip install -q -U kaleido  # vector graphics engine"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIPDkcu3oLVr",
    "outputId": "b9aaca12-c540-404f-ea8a-0b96b7e280c6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def add_task_names(fig):\n",
    "    # # sans serif\n",
    "    # fig.add_annotation(x=4, y=1.2, text='<b>Natural Language Inference</b>', xref='x domain', yref='y domain', showarrow=False)\n",
    "    # fig.add_annotation(x=0.5, y=-0.25, text='<b>Coreference Resolution</b>', xref='x domain', yref='y domain', showarrow=False)\n",
    "    # fig.add_annotation(x=4.5, y=-0.25, text='<b>Sentence Completion</b>', xref='x domain', yref='y domain', showarrow=False)\n",
    "    # fig.add_annotation(x=6.75, y=-0.25, text='<b>Word Sense</b>', xref='x domain', yref='y domain', showarrow=False)\n",
    "\n",
    "    # serif, although Colab doesn't have matching fonts\n",
    "    fig.add_annotation(x=4.5, y=1.4, text='<b>Natural Language Inference</b>', xref='x domain', yref='y domain', font={'size': 21}, showarrow=False)\n",
    "    fig.add_annotation(x=9.4, y=1.4, text='<b>Coreference Resolution</b>', xref='x domain', yref='y domain', font={'size': 21}, showarrow=False)\n",
    "    fig.add_annotation(x=5.6, y=-0.2, text='<b>Sentence Completion</b>', xref='x domain', yref='y domain', font={'size': 21}, showarrow=False)\n",
    "\n",
    "\n",
    "main_layout = dict(\n",
    "    width=1500,\n",
    "    height=700,\n",
    "    font_size=15,  # axis ticks\n",
    "    font_family='Times New Roman',\n",
    "    template='plotly_white',\n",
    "    margin_l=5, margin_r=5,\n",
    "    legend=dict(\n",
    "        yanchor='bottom', y=-0.11, xanchor='center', x=0.5, font_size=18,\n",
    "        bgcolor='rgba(0,0,0,0)', title_text='', orientation='h')\n",
    ")\n",
    "\n",
    "\n",
    "row_specs = [\n",
    "    [\n",
    "        {},\n",
    "        {},\n",
    "        {},\n",
    "        {},\n",
    "        {},\n",
    "        {},\n",
    "        {},\n",
    "        {},\n",
    "    ],\n",
    "    [\n",
    "        {},\n",
    "        {},\n",
    "        {},\n",
    "        {},\n",
    "        {},\n",
    "        {},\n",
    "        {},\n",
    "        {},\n",
    "    ],\n",
    "]\n",
    "\n",
    "MODELS = {\n",
    "    #\"mT0-13B\": mt5_xxl,\n",
    "    \"BLOOM-7.1B\": bloom_7b1,\n",
    "    \"BLOOM\": bloom,\n",
    "    \"BLOOMZ-7.1B\": bloomz_7b1,\n",
    "#    \"BLOOMZ-P3\": bloomz_p3,\n",
    "    \"BLOOMZ\": bloomz,\n",
    "#    \"mT0-13B\": mt0_xxl,\n",
    "}\n",
    "\n",
    "\n",
    "datasets_by_row = [\n",
    "    ['XNLI BG', 'XNLI DE', 'XNLI EL', 'XNLI RU', 'XNLI TH'],\n",
    "    [\"XNLI TR\", 'XCOPA ET', 'XCOPA HT', 'XCOPA IT', 'XCOPA QU',],\n",
    "    ['XCOPA TR', 'XStoryCloze MY', 'XStoryCloze RU', 'XWinograd JP', 'XWinograd RU'],\n",
    "]\n",
    "\n",
    "datasets_by_row = [\n",
    "    ['XNLI BG', 'XNLI DE', 'XNLI EL', 'XNLI RU', 'XNLI TH', \"XNLI TR\", 'XWinograd JP', 'XWinograd RU'],\n",
    "    ['XCOPA ET', 'XCOPA HT', 'XCOPA IT', 'XCOPA QU','XCOPA TH', 'XCOPA TR', 'XStoryCloze MY', 'XStoryCloze RU'],\n",
    "]\n",
    "\n",
    "flatten_dataset_names = [y for x in datasets_by_row for y in x]\n",
    "\n",
    "\n",
    "runs = ['BLOOM-7.1B', 'BLOOM', 'BLOOMZ-7.1B', 'BLOOMZ'] # 'BLOOMZ-P3'\n",
    "\n",
    "fig_specific_names = {\n",
    "    'T5+LM (11B)': 'p = 0 (T5+LM)',\n",
    "    'T0 (p = 1)': 'p = 1',\n",
    "    'T0 (p = 5.7)': 'p = 5.7',\n",
    "    'T0': 'p = 8.03 (T0)',\n",
    "}\n",
    "\n",
    "y_ranges = {  # v1 bar chart scale\n",
    "    'RTE': [0, 89],\n",
    "    'CB': [0, 89],\n",
    "    'ANLI': [15, 71],\n",
    "    'XNLI': [15, 61],\n",
    "    'WSC': [0, 81],\n",
    "    'Winogrande': [35, 71],\n",
    "    'XWinograd': [35, 71],\n",
    "    'COPA': [35, 85],\n",
    "    'XCOPA': [35, 81],\n",
    "    'StoryCloze': [35, 105],\n",
    "    'XStoryCloze': [35, 91],\n",
    "    'HellaSwag': [0, 105],  # sota?\n",
    "    'WiC': [0, 81],  # sota?\n",
    "}\n",
    "\n",
    "def box_plot(points):\n",
    "    fig = px.box(\n",
    "        points, x='runs', y='score', color='runs', points='all',\n",
    "        template='plotly_white', color_discrete_map=color_map,\n",
    "        category_orders={'runs': runs}, #labels=fig_specific_names,\n",
    "        hover_data=['prompt_name'])\n",
    "    fig.update_traces(\n",
    "        marker_size=8, marker_opacity=0.3, line_width=1.5,\n",
    "        marker_line={'width': 0.5, 'color': 'DarkSlateGrey'},\n",
    "        jitter=0)\n",
    "    return fig\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=8, vertical_spacing=0.2,#8,\n",
    "    subplot_titles=flatten_dataset_names, specs=row_specs)\n",
    "\n",
    "for row_idx, row_of_datasets in enumerate(datasets_by_row):\n",
    "    for col_idx, d_name in enumerate(row_of_datasets):\n",
    "        df_list = []\n",
    "        for model, res_df in MODELS.items():\n",
    "            d_name_full = DATASET_TO_NAME.get(d_name, d_name.lower().replace(\" \", \"_\"))\n",
    "            df = res_df[\"test\"].data.to_pandas()\n",
    "            df = df.loc[(df[\"task_name\"] == d_name_full) & (df[\"prompt_name\"].str.endswith((\"ht\", \"mt\")) == False)]\n",
    "            df[\"dataset_name\"] = d_name\n",
    "            df[\"runs\"] = model\n",
    "            df[\"score\"] *= 100\n",
    "            if len(df) != 5: print(f\"Unexpected length {len(df)} for {model} for {d_name}\")\n",
    "            df_list.append(df)\n",
    "        df = pd.concat(df_list)\n",
    "        subplot = box_plot(df)\n",
    "        for tr in subplot.data:\n",
    "            tr.showlegend = True if (row_idx, col_idx) == (1, 1) else False\n",
    "            #if tr.name in fig_specific_names:\n",
    "            #    tr.name = fig_specific_names[tr.name]\n",
    "            fig.add_trace(tr, row=row_idx+1, col=col_idx+1)\n",
    "        fig.update_yaxes(range=y_ranges[d_name.split(\" \")[0]], gridwidth=1, row=row_idx+1, col=col_idx+1)\n",
    "\n",
    "fig.update_layout(main_layout)\n",
    "fig.update_xaxes(visible=False)\n",
    "fig.update_annotations(font_size=20) # subplot title\n",
    "\n",
    "add_task_names(fig)\n",
    "fig.show()\n",
    "fig.write_image('lang_generalization.pdf')"
   ],
   "metadata": {
    "id": "fvRMPWZLoKIZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Bar plot Without seeds"
   ],
   "metadata": {
    "id": "yqnY9H6wUufF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Bar plot instead with line being variance across multiple prompts (except for 8b just put no bar)\n",
    "# group 1 of bars: epochs; group 2 of bars: shots; group 3 of bars: model params\n",
    "\n",
    "### x-axis: params ; y-axis: loss / perf ; std: seeds ; grouped by shots\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# https://coolors.co/palette/03071e-370617-6a040f-9d0208-d00000-dc2f02-e85d04-f48c06-faa307-ffba08\n",
    "\n",
    "\n",
    "PREFIX_TO_EPOCHS = {\n",
    "    \"8b7178b25b\": 7,\n",
    "    \"8b7178b35b\": 5,\n",
    "    \"8b7178b44b\": 4,\n",
    "    \"8b7178b58b\": 3,\n",
    "    \"8b7178b88b\": 2,\n",
    "    \"8b7178b178b\": 1,\n",
    "\n",
    "    \"4b284b12b\": 7,\n",
    "    \"4b284b17b\": 5,\n",
    "    \"4b284b21b\": 4,\n",
    "    \"4b284b28b\": 3,\n",
    "    \"4b284b42b\": 2,\n",
    "    \"4b284b84b\": 1,\n",
    "\n",
    "    \"2b855b1b25\": 44,\n",
    "    \"2b855b4b\": 14,\n",
    "    \"2b855b9b\": 7,\n",
    "    \"2b855b11b\": 5,\n",
    "    \"2b855b14b\": 4,\n",
    "    \"2b855b18b\": 3,\n",
    "    \"2b855b28b\": 2,\n",
    "    \"2b855b55b\": 1,\n",
    "}\n",
    "\n",
    "EPOCHS_TO_COLOR = {\n",
    "    44: \"#03071E\",\n",
    "    14: \"#6A040F\",\n",
    "    7: \"#D00000\",\n",
    "    5: \"#DC2F02\",\n",
    "    4: \"#E85D04\",\n",
    "    3: \"#F48C06\",\n",
    "    2: \"#FAA307\",\n",
    "    1: \"#FFBA08\",\n",
    "}\n",
    "\n",
    "COLORS = list(reversed([\n",
    "#    '#03071E',\n",
    "    '#6A040F',\n",
    "    '#D00000',\n",
    "    '#E85D04',\n",
    "    '#FB8500',\n",
    "    \"#FAA307\",\n",
    "    '#FFBA08',\n",
    "]))\n",
    "\n",
    "FONTSIZE = 16\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20, 12), facecolor='w', nrows=2, ncols=3, edgecolor='k', sharey=False)\n",
    "axes = axes.flatten()\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.3)\n",
    "\n",
    "GROUPS = [\n",
    "    (0, \"lm1-2b8-55b-c4-repetitions\"),\n",
    "    (3, \"lm1-2b8-55b-oscar-repetitions\"),\n",
    "\n",
    "    (1, \"lm1-4b2-84b-c4-repetitions\"),\n",
    "    (4, \"lm1-4b2-84b-oscar-repetitions\"),\n",
    "\n",
    "    (2, \"lm1-8b7-178b-c4-repetitions\"),\n",
    "    (5, \"lm1-8b7-178b-oscar-repetitions\"),\n",
    "]\n",
    "\n",
    "IDX_TO_TILE = {\n",
    "    0: \"(a) 2.8B parameters trained on C4\",\n",
    "    1: \"(b) 4.2B parameters trained on C4\",\n",
    "    2: \"(c) 8.6B parameters trained on C4\",\n",
    "    3: \"(d) 2.8B parameters trained on OSCAR\",\n",
    "    4: \"(e) 4.2B parameters trained on OSCAR\",\n",
    "    5: \"(f) 8.6B parameters trained on OSCAR\",\n",
    "}\n",
    "\n",
    "for i, base_model in GROUPS:\n",
    "\n",
    "    last_len = 0\n",
    "\n",
    "\n",
    "    epochs = list(reversed([\n",
    "        PREFIX_TO_EPOCHS[prefix.replace(\"oscar\", \"\").replace(\"c4\", \"\")] for prefix in MODEL_TO_FEWSHOT_SCORES[base_model]\n",
    "    ]))\n",
    "    colors = [EPOCHS_TO_COLOR[epoch] for epoch in epochs]\n",
    "    for shots in list(range(0, 6)):\n",
    "        scores_group = [v[shots] for k, v in reversed(MODEL_TO_FEWSHOT_SCORES[base_model].items())]\n",
    "\n",
    "        bar = axes[i].bar(\n",
    "            list(range(last_len + shots, last_len + shots + len(scores_group))),\n",
    "            scores_group,\n",
    "            #yerr=scores_std,\n",
    "            #color=COLORS[:len(scores_group)],\n",
    "            color=colors,\n",
    "        )\n",
    "        last_len += len(scores_group) + 1\n",
    "\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=FONTSIZE)\n",
    "    if i > 2:\n",
    "        axes[i].set_xlabel(\"Fewshots\", fontsize=FONTSIZE)\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Normalized Average (%)\", fontsize=FONTSIZE)\n",
    "        axes[i].legend(\n",
    "            [x for x in bar],\n",
    "            [str(x) for x in epochs],\n",
    "            title=\"Epochs\",\n",
    "            fontsize=FONTSIZE,\n",
    "            frameon=False,\n",
    "            ncol=4,\n",
    "            title_fontproperties={'weight': 'bold', \"size\": FONTSIZE},\n",
    "            columnspacing=0.9,\n",
    "            loc=\"upper center\"\n",
    "        )\n",
    "        #list(range(0, 6)), ontsize=FONTSIZE)\n",
    "        #[x for x in bar], list(range(0, 6)), title=\"Epochs\", fontsize=FONTSIZE, ncol=6, loc=\"upper center\", frameon=False)\n",
    "    if i == 3:\n",
    "        axes[i].set_ylabel(\"Normalized Average (%)\", fontsize=FONTSIZE)\n",
    "\n",
    "    axes[i].set_ylim((10, 35))\n",
    "\n",
    "    axes[i].set_xticks(\n",
    "        [len(scores_group) // 2 + (j * (len(scores_group) + 2)) for j in range(6)], list(range(6))\n",
    "    )\n",
    "\n",
    "    axes[i].grid(axis='y')\n",
    "    axes[i].set_axisbelow(True)\n",
    "\n",
    "    #legend = axes[i].legend([x for x in bar], list(range(0, 6)), title=\"Epochs\", fontsize=FONTSIZE, ncol=6, loc=\"upper center\", frameon=False)\n",
    "\n",
    "    # https://stackoverflow.com/questions/12402561/how-to-set-font-size-of-matplotlib-axis-legend\n",
    "    #plt.setp(legend.get_title(), fontsize=FONTSIZE, fontweight=\"bold\")\n",
    "\n",
    "    #handles, labels = ax.get_legend_handles_labels()\n",
    "    # Add box to legend; https://stackoverflow.com/questions/47528955/adding-a-legend-to-a-matplotlib-boxplot-with-multiple-plots-on-same-axes\n",
    "    #handles = handles[:1] + bp[\"boxes\"]\n",
    "    #labels = [str(labels[0])] + [\"Performance\"] # + OPS\n",
    "    #ax.legend(handles, labels, prop={'size': 16}, title_fontproperties={'weight':'bold'})\n",
    "    #plt.setp(plt.gca().get_legend().get_texts(), fontsize='16')\n",
    "\n",
    "    axes[i].set_title(IDX_TO_TILE[i], fontsize=FONTSIZE, fontweight=\"bold\", pad=30)\n",
    "\n",
    "\n",
    "plt.savefig(f\"epochs_scores.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UvXlrCMA0mjV",
    "outputId": "7bde7cfe-35d3-461f-b292-27775aca832f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epoch_to_models = {}\n",
    "colors = []\n",
    "for model in MODEL_TO_FEWSHOT_SCORES[base_model]:\n",
    "    prefix = model.replace(\"oscar\",\"\").replace(\"c4\", \"\").replace(\"seed1\",\"\").replace(\"seed2\",\"\").replace(\"seed3\",\"\").replace(\"seed4\", \"\")\n",
    "    epoch_to_models.setdefault(PREFIX_TO_EPOCHS[prefix], [])\n",
    "    epoch_to_models[PREFIX_TO_EPOCHS[prefix]].append(model)\n",
    "    colors.append(EPOCHS_TO_COLOR[PREFIX_TO_EPOCHS[prefix]])\n",
    "\n",
    "for shots in list(range(0, 6)):\n",
    "    scores_group = []\n",
    "    scores_std_group = []\n",
    "    for epoch in epoch_to_models:\n",
    "        scores = [MODEL_TO_FEWSHOT_SCORES[base_model][model][shots] for model in epoch_to_models[epoch]]\n",
    "\n",
    "        scores_mean = np.mean(scores)\n",
    "        scores_std = np.std(scores)\n",
    "\n",
    "        scores_group.append(scores_mean)\n",
    "        scores_std_group.append(scores_std)\n"
   ],
   "metadata": {
    "id": "qVeM93ugPPfL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epoch_to_models"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-OKpN4T7SSyj",
    "outputId": "79bd6f89-9203-4645-a8c4-111230c8c370"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for shots in list(range(0, 6)):\n",
    "    scores_group = []\n",
    "    scores_std_group = []\n",
    "    for epoch in epoch_to_models:\n",
    "        scores = [MODEL_TO_FEWSHOT_SCORES[base_model][model][shots] for model in epoch_to_models[epoch]]\n",
    "\n",
    "        scores_mean = np.mean(scores)\n",
    "        scores_std = np.std(scores)\n",
    "\n",
    "        scores_group.append(scores_mean)\n",
    "        scores_std_group.append(scores_std)\n",
    "\n"
   ],
   "metadata": {
    "id": "snPyxYsDR_lj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "last_len = 0\n",
    "epochs = list(reversed([\n",
    "    PREFIX_TO_EPOCHS[prefix.replace(\"oscar\", \"\").replace(\"c4\", \"\")] for prefix in MODEL_TO_FEWSHOT_SCORES[base_model]\n",
    "]))\n",
    "colors = [EPOCHS_TO_COLOR[epoch] for epoch in epochs]\n",
    "for shots in list(range(0, 6)):\n",
    "    scores_group = [v[shots] for k, v in reversed(MODEL_TO_FEWSHOT_SCORES[base_model].items())]\n",
    "\n",
    "    bar = axes[i].bar("
   ],
   "metadata": {
    "id": "dQUZNihTR8rD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epoch_to_models, prefix_to_color"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGkZlbu_RCxT",
    "outputId": "531097cc-261d-48a9-d0a1-cbcc29c6ed16"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "prefix_to_color"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLMdiHdGRDk0",
    "outputId": "cc0f1bca-3d9e-48ab-d0d4-36da1fc45c25"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epochs"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sNVwFAn0PeDm",
    "outputId": "fb156b5a-9263-433c-fd82-e00a414d2f74"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Multiple prompts"
   ],
   "metadata": {
    "id": "A5XLjSy0_7tN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "### Get Downstream evaluation of reproduced Scores ###\n",
    "\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "TASK_TO_BASELINE = {\n",
    "    \"anli_r1\": 1/3,\n",
    "    \"anli_r2\": 1/3,\n",
    "    \"anli_r3\": 1/3,\n",
    "    \"arc_challenge\": 1/4,\n",
    "    \"arc_easy\": 1/4,\n",
    "    \"boolq\": 1/2,\n",
    "    \"cb\": 1/3,\n",
    "    \"copa\": 1/2,\n",
    "    \"hellaswag\": 1/4,\n",
    "    \"piqa\": 1/2,\n",
    "    \"rte\": 1/2,\n",
    "    \"sciq\": 1/4,\n",
    "    \"story_cloze_2016\": 1/4,\n",
    "    \"winogrande\": 1/2,\n",
    "}\n",
    "\n",
    "REPS_TO_MODELS = {\n",
    "  \"lm1-4b2-84b-c4-repetitions\": {\n",
    "      7: \"4b284b12bc4\",\n",
    "\t    5: \"4b284b17bc4\",\n",
    "      4: \"4b284b21bc4\",\n",
    "      3: \"4b284b28bc4\",\n",
    "      2: \"4b284b42bc4\",\n",
    "      1: \"4b284b84bc4\",\n",
    "  }\n",
    "}\n",
    "\n",
    "OPS_TO_SCORES = {}\n",
    "OPS_TO_FULL_SCORES = {}\n",
    "\n",
    "OPS_TO_FEWSHOT_SCORES = {}\n",
    "OPS_TO_FEWSHOT_SCORES_BEST_PROMPT = {}\n",
    "OPS_TO_PROMPT_SCORES = {}\n",
    "OPS_TO_DATASET_SCORES = {}\n",
    "\n",
    "for BASE_MODEL, DATA in REPS_TO_MODELS.items():\n",
    "    !GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/datablations/{BASE_MODEL}\n",
    "    !cd {BASE_MODEL}; git pull\n",
    "    for REP, MODEL in DATA.items():\n",
    "        eval = pd.read_csv(f\"{BASE_MODEL}/{MODEL}/eval/merged.csv\")\n",
    "        # Columns: \"dataset\", \"fewshots\", \"prompt\", \"metric\", \"value\"\n",
    "        eval[\"normalized\"] = eval.apply(lambda x: (x[\"value\"] - TASK_TO_BASELINE.get(x[\"dataset\"], 0)) / (1 - TASK_TO_BASELINE.get(x[\"dataset\"], 0)), axis=1)\n",
    "\n",
    "        ### STD = PROMPTS ; AVG = ACROSS SHOTS & DATASET FOR SAME RANKED PROMPTS ###\n",
    "        # Varies from ~0 to 0.13\n",
    "        # Each dataset has 5 prompts; Assign an identifier to each prompt, such that\n",
    "        # the best prompt is 0, the 2nd best prompt is 1, etc. for every dataset\n",
    "        eval_prompts = eval[eval[\"prompt\"] != \"median\"]\n",
    "        eval_prompts = eval_prompts[eval[\"prompt\"] != \"average\"]\n",
    "\n",
    "        eval_prompts[\"prompt_id\"] = eval_prompts.groupby([\"dataset\", \"fewshots\"])[\"normalized\"].rank(method=\"first\", ascending=False).astype(int)\n",
    "        eval_prompts = eval_prompts.groupby([\"prompt_id\"]).mean().reset_index()\n",
    "        OPS_TO_PROMPT_SCORES.setdefault(BASE_MODEL, {})\n",
    "        OPS_TO_PROMPT_SCORES[BASE_MODEL][MODEL] = eval_prompts.normalized.values.tolist()\n",
    "\n",
    "        ### STD = SHOTS ; MEDIAN ACROSS PROMPTS & AVG ACROSS DATASET ###\n",
    "        # Varies from ~0.08 - 0.12\n",
    "\n",
    "        fewshots = eval[eval[\"prompt\"] == \"median\"].groupby([\"fewshots\"]).mean().reset_index()\n",
    "\n",
    "        OPS_TO_FEWSHOT_SCORES.setdefault(BASE_MODEL, {})\n",
    "        OPS_TO_FEWSHOT_SCORES[BASE_MODEL][MODEL] = fewshots.normalized.values.tolist()\n",
    "\n",
    "        ### STD = SHOTS ; MAX ACROSS PROMPTS & AVG ACROSS DATASET ###\n",
    "        fewshots_max = eval[eval[\"prompt\"] != \"median\"]\n",
    "        fewshots_max = fewshots_max[eval[\"prompt\"] != \"average\"]\n",
    "        fewshots_max[\"prompt_id\"] = fewshots_max.groupby([\"dataset\", \"fewshots\"])[\"normalized\"].rank(method=\"first\", ascending=False).astype(int)\n",
    "        fewshots_max = fewshots_max[fewshots_max[\"prompt_id\"] == 1].groupby([\"fewshots\"]).mean().reset_index()\n",
    "\n",
    "        OPS_TO_FEWSHOT_SCORES_BEST_PROMPT.setdefault(BASE_MODEL, {})\n",
    "        OPS_TO_FEWSHOT_SCORES_BEST_PROMPT[BASE_MODEL][MODEL] = fewshots.normalized.values.tolist()\n",
    "\n",
    "\n",
    "        ### STD = DATASET ; MEDIAN ACROSS PROMPTS & AVG ACROSS SHOTS ###\n",
    "        # Varies easily from 0 to 0.5\n",
    "\n",
    "        fewshots = eval[eval[\"prompt\"] == \"median\"].groupby([\"dataset\"]).mean().reset_index()\n",
    "\n",
    "        OPS_TO_DATASET_SCORES.setdefault(BASE_MODEL, {})\n",
    "        OPS_TO_DATASET_SCORES[BASE_MODEL][MODEL] = fewshots.normalized.values.tolist()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QI52YqcysVLH",
    "outputId": "2b966d78-696f-4e21-8c4c-f6c67ea2c45d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "OPS_TO_FEWSHOT_SCORES"
   ],
   "metadata": {
    "id": "uaIBLw9jyy4V"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://coolors.co/palette/03071e-370617-6a040f-9d0208-d00000-dc2f02-e85d04-f48c06-faa307-ffba08\n",
    "COLOR_MAP = {\n",
    "    7: '#03071E',\n",
    "    5: '#6A040F',\n",
    "    4: '#D00000',\n",
    "    3: '#E85D04',\n",
    "    2: '#FB8500',\n",
    "    1: '#FFBA08',\n",
    "}\n",
    "\n",
    "LOSSES = [\n",
    "  2.525268077850342,\n",
    "  2.483349323272705,\n",
    "  2.4695968627929688,\n",
    "  2.4654414653778076,\n",
    "  2.468310832977295,\n",
    "  2.4483046531677246\n",
    "]\n",
    "\n",
    "EPOCHS = [7, 5, 4, 3, 2, 1]\n",
    "\n",
    "PARAMS_TICKS = [100e6, 300e6, 1e9, 3e9, 6e9, 30e9]\n",
    "PARAMS_STR = [\"100M\", \"300M\", \"1B\", \"3B\", \"6B\", \"30B\"]\n",
    "\n",
    "\n",
    "LOSS_MIN = 1.8\n",
    "LOSS_MAX = 2.9\n",
    "\n",
    "SHOTS = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))#, nrows=2, ncols=2)\n",
    "\n",
    "\n",
    "ax.plot(EPOCHS, LOSSES, 'x', markersize=10, mew=4, color=\"#9D0208\", label=\"Loss\")\n",
    "ax2 = ax.twinx()\n",
    "ax2.boxplot(OPS_TO_FEWSHOT_SCORES['lm1-4b2-84b-c4-repetitions'].values(), positions=list(reversed(EPOCHS)))\n",
    "\n",
    "ax.set_xlabel(\"Epochs\", fontsize=12)\n",
    "ax.set_ylabel(\"Validation loss\", fontsize=12)\n",
    "ax2.set_ylabel(\"Rescaled performance\", fontsize=12)\n",
    "\n",
    "ax.set_xticks(list(reversed(EPOCHS)), fontsize=12)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "\n",
    "ax.grid(axis='y')\n",
    "\n",
    "ax.legend(fontsize=12)\n",
    "plt.savefig(\"epochs_performance_multiple_prompts.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "zRJqoiyjywVL"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}